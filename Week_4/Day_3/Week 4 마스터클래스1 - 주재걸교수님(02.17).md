# Week 4 마스터클래스1 - 주재걸교수님(02.17)

## Q&A 세션

- 교수님께서 세부 연구분야를 선정하실 때 어떻게 결정하셨는지 스토리가 궁금합니다. P stage에서 nlp, vision 등 하위태스크를 결정해야하는데 이때 참고할 만한 팁이 있을까요?
	- nlp와 컴퓨터 비전이 딥러닝의 홈그라운드.
	- 자연어처리쪽을 담당해서 강의를 준비하긴 했지만, 지금 현재는 컴퓨터비젼을 더 많이 연구하고 있습니다.(대략60~70 컴퓨터비전, 20~30 nlp, 나머지 시계열데이터, 텍스트/데이터마이닝)
	- 비전쪽이 연구하기에 더 수월한 분야는 맞는거같습니다.
		- nlp쪽은 대규모 데이터나 self-supervised learning의 pre-training이 대세가 된것같습니다. 이 경우 데이터나 GPU 리소스 확충이 힘들긴 합니다. GPT-2,3 등은 교수님도 언감생심 연구하기 힘들다고 생각하고 있습니다.
		- 따라서 접근성은 비젼쪽이 좀 더 좋습니다.
	- 산업현장이나 구직시장이나 커리어를 고려할 때에는 nlp쪽도 괜찮습니다. 상대적으로 하는 사람이 적은데, needs는 nlp쪽이 꽤 있어서 괜찮은 시장인거 같습니다.
		- 연구실 컨택에도 자연어처리 관련된 학생 추천해달라는 요청이 많습니다.
	- 비젼은 비젼대로 발전확률이 높고, 성공확률도 높지만, 하는 사람이 많기때문에 경쟁이 심합니다.
	- NLP쪽은 힘들지만 좋은 기회가 많습니다.
	- 한 분야를 파다가 다른 쪽으로 스위칭하기도 꽤 용이하니까, 처음부터 뭘 시작할지 깊이 고민하기보다는 조금 더 끌리는 걸로 시작하세요.
	- 페이스북 커뮤니티나 reddit쪽에서 흥미로운 기술 모니터링하시면서 트렌드를 잘 보시면 됩니다.
- 신입 AI 개발자에게 요구하는 역량은 어느정도라고 생각하시나요? 혹은 이정도는 알고 취업을 하는게 좋겠다 라는 정도의 기준이 있나요?
	- 학교에 있다보니까 사실 산업계쪽의 AI 개발자에게 요구하는 역량이 어떤지는 감이 잘 안오긴 합니다.
	- 네이버나 메이저 회사를 포함해서 서류/코테 등이 있는 회사는 AI 관련 모델 빌딩이나 성능을 올리는 능력도 요구하지만, 알고리즘/자료구조 등 관련된 기초 CS지식도 많이 필요로합니다.
		- 연구실에서 NLP를 열심히 잘 하는 친구 인터 소개시켜줬더니, 코테 1차 탈락하더라구요(…)
		- 제공되는 오픈 소스 API를 사용해서 메모리를 효율적으로 사용하는 방법 같은것도 고민을 해보는게 좋을것같습니다.
		- CS 기초를 같이 공부해두시는게 좋은것같습니다.
	- AI에서는 수학적 배경지식도 꽤 중요합니다.
	- 산업계에서는 AI 핵심기술도 중요하지만 파이프라인을 다 개발해서 서비스로 만드는 기술도 중요합니다.
		- 소프트웨어 개발의 여러 모듈을 생각할때, AI 모듈은 전체에서 얼마 되지 않는 비율입니다.
		- 풀스택개발자같은 용어가 있듯이, 여러 분야의 지식이 있으면 좋을 것같습니다.
	- 딥러닝쪽에서는 이 과정 내에서 커버가 되는 MLP, CNN, RNN, 어텐션, backpropagation, loss function의 기본적 원리 등… 이런거가 중요하고
		- 발빠르게 트렌드를 캐치해내고 모델로 구현하는 능력
		- 영어논문을 빠르게 읽고 이해할 수 있는 능력
		- 코드를 잘 이해할 수 있는 능력
- 반어법이나 돌려말하기 등 (같은 문장이라도) 실제로 어떤 문맥과 의도를 가지고 있는지를 분석하는 화용(pragmatic)분석에까지 높은 성능을 보이는 모델은 아직 못 본 것 같은데, 이런 연구가 어떻게 진행되고 있고 앞으로 어떻게 될지, 교수님은 어떤 생각을 가지고 계신지 궁금합니다.
	- 감정분석 task 등에서도 이미 반어법이나 전체적인 맥락을 보고 문장의 의미를 파악하는 것이 long-standing-problem이었습니다. 오래전부터 challenging하고 많이들 노력하고 있는 일입니다.
	- GPT-2,3, BERT같은 여러 변종 모델들이 그냥 많은 데이터, GPU, Layer로 해결하려고 하는 경향이 있는데, 사실 교수님 스스로도 단순히 그렇게 하는게 정말 NLP에 있어서 그런 문제들을 풀수 있는가 하면 솔직히 확신을 못하겠습니다.
		- NLP를 정복하면 사실 범용인공지능이 완성되는게 아닌가 하는 생각도 듭니다.
		- 특정 task에 특화한 모델 자체가 이런 어려운 문제들을 해결하는 것에 큰 도움이 되지는 않는게 아닌가 하는 생각이 듭니다.(적어도 NLP쪽에서는)
	- 이런 점에 있어서는 공유드릴만한 insight가 사실 부족한거같네요.
	- 게리 마커스같은 분들이 계신데, 복잡다단한 추론을 그냥 general purpose로 만든 레이어를 무지막지하게 쌓으면 되지 않냐고 하곤 합니다.
		- 근데 데이터나 모델 사이즈만으로 쭉 승부를 봐서 이 영역이 정복이 될지는 잘 모르겠습니다.
		- 사람의 손이 들어가서 모델도 좀 바뀌고 하는게 해결책이 될지는… 교수님도 지켜보고 있습니다.
- 많은 NLP 데이터를 구할 때 인터넷이 방대한 자료의 소스가 될 것 같은데, 웹의 여러 텍스트 데이터를 크롤링 하는 것도 현업에서 많이 쓰이나요? 크롤링이 산업 현장에서 NLP 딥러닝 엔지니어에게 유효한 기술 스택인지 궁금합니다.
	- 네. 필요한 기술스택이라고 봅니다.
	- 데이터 수집/정제를 외주 업체에 의뢰하는 경우도 있는데, 자금사정 등이 있을 경우 직접 크롤링을 해서 데이터를 수집하는 경우도 많이 있습니다.
	- 연구실에서도 크롤링을 심심찮게 많이 합니다.
	- 교수님도 크롤링을 할줄 모르긴 하는데, 학생들이 크롤링 자체에 크게 어려움을 겪지는 않는거같긴합니다.
		- reverse 엔지니어링같아서 좀 이질적인 코딩이긴한데, 그래도 쓰이니까…
		- 모르는건 걸림돌이 될수도 있다는 생각이 들긴 합니다.
- AI를 공부하다 보면, 신기하면서도 한편으로는 직관적으로 와닿지 않아 답답한 느낌이 있습니다. 교수님께서는 이 부분을 받아들이고 넘어가시나요? 이런 점들 때문에 공부를 지속하기 힘들어 지쳐가는데요, 딥러닝 분야를 공부하면서 계속해서 연구할 수 있게 하는 본인만의 원동력이 있으신가요?
	- 요즘은 전반적으로는 협업의 중요성이 대두되는것같습니다.
	- 여러 사람들이 같이 일을 해서 한 task를 빠르게 해결하는 것이 sight가 빨라지는 길인것 같습니다.
		- 혼자 공부를 하는데에는 한계가 있다고 생각이 들어서, 어떤 형태로든 주변에 마음맞는 분들과 discuss를 자주 하시길 바랍니다.
		- 그게 좀 지칠때의 재미가 되고, 식견을 넓히는 계기가 될 수도 있습니다.
	- 똑같은 걸 봐도, 어떤 사람은 1만큼을 보고, 어떤 사람들은 10만큼 보는 경우가 있는데, 그런 측면에서는 '이렇게 했더니 잘됐다’를 '그런가보네’하고 넘어가는게 아니라 '이게 왜 안될까, 왜 될까’에 대한 원인을 자꾸 끊임없이 분석하고 시도해보는게 중요한 것같습니다.
		- 깊이있는 분석과 방향성을 가지고 연구를 했을때 성과가 나오는 경우가 많은것같아요.
	- 뭐가 안되기는 쉬운데, 잘되기는 확률적으로 어렵기때문에, 잘된 것과 안된 것의 그 원인을 비교 분석해보려고 시도해보는게 좋은 것 같아요.
- GPT-3 를 활용하려 할 때, 네이버 같은 회사가 아니고서는 학습시킬 수가 없어서, OpenAI 의 허가를 받아야 하는 것으로 알고 있습니다. 개인이나 작은 단체는 이런 모델을 어떻게 학습하고 활용할 수 있을까요? 앞으로 더 규모가 큰 모델이 나온다면 어떻게 대처해야할까요?
	- 풀리지 않는 고민이고, 네이버나 교수님을 포함해서 많은 연구자들이 고민하고 있는 부분입니다.
	- 방법이 있는지는 잘 모르겠습니다. OpenAI는 자본력이 있으니까…
	- 규모의 경제가 AI 발전을 주도하고있는데, 넋놓고 바라볼 것이 아니라 최소한 돌려볼수는 있어야한다고 생각은 하지만…
		- 그런게 힘들긴 합니다.
		- 네이버도 큰 투자를 통해서 catch-up을 잘하고 선도적으로 하려고 노력을 많이 기울이는걸로 알아요.
	- 필요한 모델과 데이터를 얻기 위해 어디와 같이 협업을 해야할 지 고민을 조금 해봐야하지않을까 싶네요.
- 채용공고 기준으로 CV분야를 더 많이 찾아볼 수 있는데, 시장에서 NLP의 실제 수요는 어떨까요? AI 엔지니어로서 NLP분야의 서비스를 구현하는데 있어서 무엇을 공부하고, 어떤 함정들을 조심해야할까요? (언어학적 지식이나, 데이터 활용의 윤리적 문제 등)
	- 개인적으로는 전략적으로 구직 시장에서 더 유리한 것은 NLP쪽이라고 생각합니다.
		- 물론 실적이나 내세울 게 있어야 하겠죠.
	- github에 본인이 짠 코드나 모델들, 연구쪽을 올려두는게…
	- 어찌됐건, 본인의 내실을 다지는 게 중요합니다.
		- 실력도 있고 코딩도 잘하고 엄청 오랫동안 공부한 친구가 있는데, 외부적으로 내세울만한 실적이 없으면…
		- 평가받을 기회도 있어야 하고 평가하는데 시간도 걸리니까…
		- 외부로 보이는 스펙을 좀 신경을 쓰는게 당연히 필요합니다.
	- 교수님은 시장에서 NLP 수요가 많은데에 비해서 공급자가 적다고 하는 걸 많이 들어서 전망은 밝다고 봅니다.
- 박사 유학에 관심이 있는 학생입니다! 교수님께서도 석박을 해외에서 하신 것으로 알고 있는데 ML 분야에서, 넓게는 CS 분야에서 박사유학에 대한 교수님의 의견이 궁금합니다(장단점 등).
	- 추천하는 바입니다.
	- 넓은 세계에서 견문을 넓히는 점에서 좋은 기회입니다.
	- 다만 ML이나 인공지능 연구로 봐서, 솔직히 연구 수준이 상향평준화된거같긴 합니다.
		- 이전에는 탑 대학교 연구실의 연구가 정말 질적으로 달랐습니다.
		- 그런데 요즘은 중국, 유럽, 한국에서도 연구나 실력이 상향평준화 되어서 굳이 외국에 가서 공부해야하는지는…
	- 그래도 외국에 가면 외국 기업에 취직할 수 있는 확률이 훨씬 높아집니다.
	- 외국 취직을 위한 교두보로 유학은 좋은것같습니다.
		- 돈이 많이 드는데, 요새 대우가 좋아져서 정–말 열심히 한다면 가서 취직해서 갚을수도 있다고 생각합니다.
- 방금 말씀해주신 부분의 연장선상인데, 실적 위주로 달성하려면… 연구 관련 공부를 위해 탑 다운 방식의 접근 방식이 좋을까요?? 딥러닝 관련하여 공부해야 할 요소들이 매우 많은데, 바닥부터 관련 개념들을 다 섭렵해가며 공부하자니 시간이 너무 많이 드는거 같습니다
	- 최근에 나온 논문들을 위주로 공부할지 기초부터 공부할지…
	- 답이 없는거같아요. 교수님도 이런 고민을 합니다.
	- 가중치를 얼마나 둬서 하느냐는 본인 선택인것같습니다.
		- 기초 공부만 하다보면 지루하고 어디다 쓰는지 모르겠고…
		- 어려운거만 하다보면 도저히 못하겠고…
	- 솔직히 교수님도 optimization 쪽 이론은 잘 모릅니다.
	- 무엇을 공부해야하는 하는지 빅픽쳐를 좀 그려놓고, 세부 로드맵을 그려 방향성을 좀 가지고 있는게 좋은것같습니다.
- 해외 온라인 석사는 어떻게 생각하시나요?
	- 솔직히 내실이 그렇게 있는 것 같지는 않습니다.
	- 돈을 지불하고 온라인 강의를 통해서만 배울수 있는 지식은 요새는 잘 없는것같습니다.
		- 지천에 지식이 널려있고, 저렴한 가격으로 온라인 교육도 잘 되고있으니까…
	- 배우기 위해 온라인 학위를 하는것은 가치가 있는지 잘 모르겠습니다.
- 저는 프론트엔드에 관심이 많습니다. AI와 백엔드와의 결합은 쉽게 떠오르는데 프론트엔드 단에서의 AI 기술 결합은 어떤게 존재할지 궁금합니다. 또한 이러한 분야를 공부하기 위해서는 어떤 부분을 추가적으로 살펴봐야 할까요?
	- 프론트 관련하여 깊이있는 이론이나 백그라운드 지식이 잘 없긴 합니다.
		- fundamental한 부분보다는 사용자와의 접점을 vertical하게 파고있습니다.
	- 개인적으로는 유망한 분야라고 생각합니다.
		- 프론트 엔드는 개발자의 effort가 너무 heavy합니다.
	- 정통적인 기법(CV 등)을 연구하는 건 많은데, 프론트를 터치하는 연구는 많이 없습니다(가성비가 조금 떨어져서)
		- 그렇지만 필수적인데, 간과되고 있는 부분이 많은 것 같습니다.
	- human computer interaction 쪽을 찾아보시면 좋을것같고, CHI 학회, data visualization, UI를 통해 AI를 활용할 수 있는 system을 만드는 분야를 찾아보시면 좋을것같습니다.
	- 여러 학회쪽에서도 UI까지 조금 포함한 논문들이 어느정도 있습니다. 그런것들을 주의깊게 보셨다가 사용자 관점에서 어떤 개선을 할 수 있을지 고민해보면 좋을것같습니다.
	- 결론적으로 유망하다만, 공수가 좀 많이 듭니다.
- 대학원을 가는 목적이 연구가 아닌 취업이 목적이라면 어떻게 생각하시나요? 취업을 위해서 석사 학위가 필요한 경우가 많다고 생각해서 석사까지 하고 취업할 생각을 하고 있는데, 교수님의 의견이 궁금합니다
	- 이런 케이스들을 많이 보긴 했습니다.
	- 학사 졸업하고 취업하신 분들에게는 중요한 일을 안맡기고, 석/박사가 꿰차는 경우가 있다는 이야기를 듣긴 했습니다.
		- 학부만 졸업했다고하면 따로 석/박사 소지자보다 더 잘하고 경력이 많은 사람들이 대부분입니다.
	- 기본적으로는 인공지능 과정이 솔직히 학부수준보다는 대학원수준에서 포진되어있습니다.
		- 학부과정에서 깊이있게 다루기에는 교과과정을 flexible하게 다루기 힘들어서.
	- 최소 석사학위 이상을 찾는 경우를 많이 보았고, 그런 요소 때문에 바로 취업을 준비하다가도 석사로 들어오는 사람들을 많이 봤습니다.
	- 그런 의미에서 사실 괜찮은 선택인것같고, 2년정도 공부 더하는거야 뭐…
		- semi-사회생활, 조직생활을 경험한다고 생각해보면 좋을것같아요.
		- 나쁘지 않은 투자입니다.
		- 망하진 않습니다. 평균적으로 조금 더 좋은 기회가 많을 것 같습니다.
	- 그렇지만 본인이 스타트업/사업아이템 쪽에 관심이있다면, 석사 하고 나서 창업했을 때 세상이 어떻게 바뀌어있을지 몰라서… 대학원에서의 2년이 크게 도움이 안될수도 있습니다.
		- 인생은 타이밍이니까…
		- 하이리스크 하이리턴이지 않을까…
- 강의중 쉬운 예제를 많이 주셔서 이해가 잘 되었습니다. 모델구조를 볼 때 쉬운 예제를 들어서 이해하는게 결과적으로 더 좋을까요?
	- 저 스스로도 어려운 예를 들면 이해가 안되는 경우가 많더라구요.
	- 직관적으로 수식이 무슨 의미인지… 이런게 이해할 때 답답한게 많았습니다.
	- 한마디로 명쾌하게 설명할 수 없으면 제대로 아는게 아니라는 개인적인 생각이 있어서, 부모님에게 설명할 수 있을 정도로 꿰차고있다! 정도가 깊이 있게 아는것 아닌가 싶습니다.
	- 복잡한것을 만났을 때에 좀 더 simple한 예를 만들어서 learning example을 머릿속에 두고 사용합니다.
	- 또는 설명을 잘하는 동료나 선배들에게 물어보면서 설명을 듣는것도 좋은것같습니다.
- 퍼포먼스 향상을 위해서 C을 사용하는 것으로 알고 있습니다. 애초에 python에서 사용하는 모듈이 C 혹은 C로 구현되어 있는데, C++을 사용하는 것으로 큰 성능 향상을 얻을 수 있나요?
	- 네.
	- 일례로는, pytorch나 tensorflow는 메모리 수준의 코딩이 힘듭니다.
	- 임베디드 시스템, 엣지디바이스에서 딥러닝을 돌리거나, 스마트폰 앱단위의 딥러닝은… 하드웨어 자체를 고려해야 실질적으로 성능 향상을 꾀할 수 있습니다.
		- 물론 어렵습니다. 신경쓸것도 훨씬 많습니다.
	- 근데 솔직히 다 공부하는 건 힘들기 때문에, 전체적으로 빅픽쳐 정도는 가지고 있어야한다고 생각합니다.
		- 메모리 누수, 쓰레드가 어쩌구 하는 말들은 이해해야 하지 않을까 싶네요.
		- OS, 컴파일러같은 CS 기초과목들을 보는게 어떤지.
	- 모델 경량화, 스마트폰 배터리를 덜 소모하는 그런 모델들… 고민하다보면 low level로 가게됩니다.
- 자연어처리 석사생으로 대화 에이전트의 발화 생성에 관심을 가지고 연구중입니다. NLP 분야는 트랜스포머 이후로 업계 트렌드가 빠르게 발전하여 연구자로서 커버해야 하는 양이 많습니다. 시간이 부족하다고 느끼는데요 성공적인 논문을 쓰고 졸업하기 위해 알려주실 수 있는 연구 팁이 있을까요?
	- 딱히 팁은 모르겠고, 그냥 협업을 잘하는게 좋지 않을까 싶네요.
		- 본인이 속한 그룹이 인공지능 커리어를 쌓는게 도움이되는 사람들에게…
		- 두 사람이 각자 하나씩 논문을 쓰는것보다 두 논문을 공동으로 쓰는게 더 빠른 시간내에 좋은 연구를 할 수 있는 경우가 많습니다.
	- 큰 틀에서는 인간관계, 커뮤니케이션 스킬도 중요하겠네요.
- 교수님의 랩실 학생 선발 기준이 궁금합니다!
	- 일관된 기준이 있지는 않은 것 같고…
	- 기초적인 내용들을 깊이있게 알고있고… ㅎㅎㅎ
	- 어떻게 말해야할지 모르겠네요.
	- 연구실 FAQ 참고하세요 ㅎㅎ
- LSTM 이나 GRU 가 transformer 이후로 패러다임이 바뀌었다고 들었는데, LSTM 이나 GRU 의 실용적 유통기한은 어느정도 일 것이라 보시나요?
	- 저도 의문인데, 강의에 포함하긴 했지만 실제로는 요새 attention으로 다 대체되었습니다.
	- 그렇다고 사장된 기술이라고 판단하기에는 섣부른것같고, 구글에서 Medical 데이터를 가지고 이런저런 연구를 하신 지인분들 얘기를 들으면, 시퀀스 데이터나 시게열 데이터 쪽에서는 아직도 LSTM이나 GRU 등이 더 성능이 잘나오는 경우가 많다고 합니다.
		- 그래서 꾸준히 쓰이는 곳은 있지 않을까 하네요.
	- long-term dependency를 transformer가 해결했는데, 사실 temporal data가 중요한, short-term 데이터가 중요한 영역에서는 사실 LSTM이나 GRU가 더 좋을 것 같습니다.
		- 주가 데이터같은것들
- 교수님이 생각하시기엔 인공지능이 또다시 침체기를 겪을것이라 보시나요?
	- 일단은…인공지능 기술 자체의 발전은 어느 정도 정체가 되거나 포화될 수도 있을 거라 봅니다만, 여러 다양한 도메인에서…데이터가 많이 쌓여있있어서, 여기에 인공지능 기술을 잘 적용함으로써 큰 가지를 만들어낼 수 있는 분야가 아직 여전히 무수히 많다고 생각되어서, 이번에는 그래도 인공지능 분야가 오래 가지 않을까 생각됩니다.
	- 다만 그만큼 정말 많은 분들이 이 쪽 분야에 뛰어들고 있는 만큼, 본인의 경쟁력이나 유니크한 장점으로 어떤 것을 가져갈지…(가령 특정 도메인의 지식, 수학적으로 깊이있는 배경 지식, AI서비스의 기획력 등) 항상 고민하는 것이 중요하지 않을까 합니다~

- Week 4 마스터클래스1 - 주재걸교수님(02.17)
	- [Q&A 세션](https://hackmd.io/6RMuuDrFT32LJB2KWbOhtw?view#QampA-세션)

[Expand all](https://hackmd.io/6RMuuDrFT32LJB2KWbOhtw?view#)[Back to top](https://hackmd.io/6RMuuDrFT32LJB2KWbOhtw?view#)[Go to bottom](https://hackmd.io/6RMuuDrFT32LJB2KWbOhtw?view#)

Select a repo