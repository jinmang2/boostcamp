# Week 7 금요일 마스터클래스 - 오태현 교수님(03.12)

POSTECH 전자전기공학과 교수

## Q&A

- 마스터님은 다양한 경험을 하신 것으로 알고있습니다. 만약 학부로 돌아간다면 어떤 공부나 활동을 하실것같으신가요? 또, 현재의 전공을 선택하게된 계기와 자신의 한계를 돌파하시는 원동력은 무엇인지도 궁금합니다.

	- 학부때 공부는… 충분히 많이해서 더 하고싶진 않네요…ㅎ
	- 다시 돌아가도 할것이라고 생각하는건 수학공부이고, 사실 지금도 하고있습니다.
	- 공학수학 / 물리/ 수치해석 등 여러 수학을 공부했었지만 부족한 것 같아요.
	- 활동적인건…
		- 해외 여행을 한번도 못가본게 아쉽네요. 해외를 안나가봤다 보니 영어 논문 읽고 쓰는데도 어렵더라구요.
		- 석사때 처음으로 해외를 나가봤는데, 해외 단기로 나가서 interaction해보니 확실히 달랐어요.
		- 단기로 살아보는것(3개월정도)이 좋겠지만, 짧은 시간이라도 여행을 다녀오는게 커리어에도 도움될것같아요.
	- 계기는 차치하고 한계 돌파를 말씀드려보자면…
		- 한번에 한계를 완전히 넘을 수 있는가?는 잘 모르겠어요.
		- 운동하는 것 처럼 조금씩 조금씩 한계선 근방에서 challenge를 하다보면 늘더라구요. 뇌도 비슷한 것 같아요.
		- 그리고 마인드셋을 좀 잘 잡고 좌절하지 않는게 좋은것 같아요.
			- 내가 공부하기 좋은 환경을 만들고, 공부가 아니라 좋아하는 일을 하는거라고 생각(세뇌)하기
		- 롤플레이를 하면서 하다보면 잘되기도 합니다.
			- 발표를 한다 - 나는 지금 영업하는 세일즈맨이야, 문서작성을 한다 - 변호사가 된것처럼 글쓰기…
			- 내가 못했던 걸 다른 직업을 가진사람들은 어떻게 했을까? 이런 레퍼런스를 찾으려고 노력을 많이 했습니다.

- 교수님께서는 동기 부여를 중요하게 생각하시는 것 같습니다. 어떤 계기로 공부를 해야겠다 생각하셨는지, 왜 해당 도메인을 선택하신 건지, 어떤 삶을 위해 교수님이 되셨는지 궁금합니다.

	- 굉장히 포괄적인 질문인데… ㅎㅎ
	- 동기부여 : 추운 겨울에 밖에서 일해보면 따뜻한 곳에서 앉아서 하는 사무직이 하고싶다는 생각이 들거에요…ㅋㅋㅋ
	- 공부를 해야겠다는 생각을 왜 했는가?하면
		- 중-고등학교 때 게임을 좋아했었고, 컴퓨터를 잘하면 게임을 할수 있을 것 같았고 웹디자이너 같은 직업을 가지지 않을까하는 생각을 했죠. 그래서 컴공 들어갔어요.
		- 근데 들어가보니까 수학같은걸 배우면서 뭔가 원리를 배우는게 아니라 그냥 외우는것만 같더라구요. 똑똑한 사람들이 만들어 놨으니까 넌 따라만 해라, 그런 느낌?
			- 근데 사람들이 디자인한 거에는 간과한 부분이 분명히 있잖아요. 퓨리에 변환같은 방식들도 그렇고… 그래서 솔직히 좀 이건 좀 아쉬운 방식이라는 생각이 들었어요.
		- 마침 그 때쯤 들었던 PC수업과 수치해석 수업시간에 공부했던 것은 대량의 데이터를 다루는것, 그리고 데이터로 패턴인식을 하는거였어요.
			- 그건 인간이 간과하는 문제들을 해결할 수 있겠다고 느꼈어요. 그래서 이게 제 길이라고 생각했어요.
	- 어떤 삶을 위해 교수님이 되셨는지 궁금합니다라는건…
		- 내가 아는걸 가르쳐주고 싶은 마음도 있었고, 교수가 안정적인 직업인것도 있었고…
			- 근데 공부하면 할수록 내가 모르는게 너무 많다는 생각이 들고 부끄럽다는 생각이 들죠.
			- 아예 모르는 사람들한테 쉽게 가르친다는건 너무 어려워요. 1+1을 가르치는게 제일 어렵잖아요.
		- 그래서 또 연구를 하면 동료 연구원들과 연구하는게 너무 재밌더라구요. 팀원들과 머리도 맞댈 수 있고.
		- 근데 내가 원하는 창의적인 연구를 할 수 있는 곳이 잘 없으니까, 차라리 교수를 해서 똑똑한 학생들과 함께 창의적 연구를 해보자는 생각을 했어요.
	- (질문) 컴퓨터 소프트웨어와 컴퓨터 공학과 중 컴퓨터 공학과를 선택한 이유가 있으실까요?
		- 컴퓨터 공학과는 컴퓨터 소프트웨어에 비해 좀더 하드웨어와 interaction하는 코딩(임베디드, 어셈블리)을 하고, 컴퓨터 소프트웨어는 웹/게임 프로그래밍 등을 합니다.
		- 그런데 솔직히 말하면 컴소에서 하는 그런 프로그래밍에는 원래부터 잘하던 친구들도 너무 많고 이길 수 없겠다는 생각이 들어서, fundamental하게 좀 더 차별화해서 경쟁력을 가지려면 컴공으로 가야겠다는 생각을 했습니다.

- 강의에서 굉장히 다양한 논문들을 소개해주셨는데, 강의를 준비하실 때 기대하셨던 학생들의 이해 수준은 어느정도였는지 궁금합니다.

	- 아마 굉장히 많은 논문을 제공해줘서 다 이해하기 분명히 어려웠을거에요.
	- 100%는 기대하지 않았고, 5일만에 Computer Vision를 마스터하겠다? 그건 너무 말도 안되죠.
		- 10개의 강의에서 가르친 내용은 현재 논의되고있는 토픽의 반도 안돼요.
	- 다만 몇몇 토픽 상에서 ‘어떤 흐름이 있다’ 정도를 다루려고 노력했어요.
	- 가르친 10개의 강의 중 {data efficient : 굉장히 실무적인 기술, visuliazation : 디버깅 툴}
		- 이 두개정도는 좀 중요하다고 생각되어서 세세하게 다루긴 했는데, 나머지는 그냥 흐름들을 짚어가시면 돼요.
	- 만든 강의는 CS-231n보다 조금 더 강의 난이도가 낮은 수준이에요. CS-231n은 석사 대상이고, 이 강의는 학사 3-4학년 타겟으로 스코프를 잡았다고 생각할 수 있을것같아요.
	- 코드를 보고 이 파트가 강의 내의 아키텍쳐 다이어그램에서 어느 위치인지 짚을 수 있고, 몇몇 부분들을 수정이 조금 가능한 정도가 목표였어요.(중급)
		- 과제 코드가 짧긴 하지만, 막상 작성하는게 되게 어려웠을거에요. 결국은 그 부분이 아니라 전반적인 구조를 이해해야 작성할 수 있는 부분들이라서…

- CV 분야는 다른 딥러닝 분야보다 기술이 빨리 발전했기 때문에 높은 수준의 기술을 가진 사람들도 상대적으로 더 많을 것 같습니다. 현재 CV 분야의 회사나 대학원에서는 어느 정도 수준의 구현 능력을 기대하는지 궁금합니다.

	- 상대적으로 굉장히 인력이 많을 것 같지만, 생각보다 회사에서 요구하는 조건을 만족시키는 사람은 진짜 거의 없어요. 굉장히 찾기 힘들어요.
	- 그래서 본인이 이왕 뛰어든 김에 좀 더 차별화하고 제대로 해보겠다 하면 수요는 반드시 있다고 생각하시면 될 것 같아요.
		- 외국 기업도 그렇고, 국내 기업도 그렇고 항상 사람을 못뽑아서 안달이에요.
	- 지금 채용시장이 요구하는 부분이 아직은 어떤 bar처럼 작용해서 그렇게 느끼실수도 있어요.
		- 그런데 계속 공부하다보면 그 허들이 생각보다 그렇게 높진 않구나 하고 생각할수도 있습니다. 그렇게까지 높은 수준을 필요로 하진 않아요.
	- 어느정도를 기대한다… 이건 role에 따라 달라요.
		- 회사에서는 AI 기획, AI 엔지니어, AI 리서쳐가 있죠.
			- 기획은 GCP,AWS같은 플랫폼들이나 오픈소스를 사용해서 노코드/로우코드 패러다임을 적용시켜 아이디어를 검증하기만 하면 됩니다.
			- AI 엔지니어와 AI 리서쳐는 요구하는 코딩 수준이 비슷해요. 엔지니어가 조금 더 잘하기는 해야하지만.
				- 그러나 AI 엔지니어가 일반적인 SW 엔지니어같은 업종만큼 코딩을 요구하지 않아요. 절대 그렇게 어렵지 않습니다.
				- 대신에, 버그를 생성하지 않는 꼼꼼한 코딩과 sharing 가능한 코드 작성, 그리고 빠른 prototyping 능력이 필요합니다.
				- 진짜 소프트웨어 엔지니어들보다는 코딩 요구능력은 낮습니다.
					- 이번 과제를 보면서 수정같은 것이 크게 어렵지 않았다면 여러분들은 충분히 재능있는 거에요.(이번 과제 난이도가 좀 있는 편이었다고 말씀하셨습니다)

- 각 강의마다 다양한 모델들에 대해서 설명해주시는데 현재 제한된 시간내에 강의를 수강하는 수강생의 입장에서 각 모델들에 대한 이해를 어느정도 하는게 좋을까요? 예를들어 각 모델들에 대한 논문이나 코드를 자세히 본다던지 아니면 모델에 대한 전체적인 구조와 원리정도만 짚고 넘어가는게 좋을지 또는 대표적인 모델에 대한 논문과 코드만 구체적으로 공부할지 교수님의 의견이 궁금합니다. 또한 현업에 계셨을땐 어느정도로 모델에 대해 이해하시고 그 모델을 사용하셨는지도 궁금합니다.

	- 모든 걸 다 이해하는건 기대하지 않았고, 처음 듣고나서 80% 정도만 이해해도 엄청 잘한거에요.
		- 한번에 다 이해할 필요도 없고 그럴수도 없어요. 솔직히 그건 오만 아닐까요?
	- 강의에서는 대표적인 논문들을 집어줬지만, 논문들을 다 훑어보고 할 필요는 없이, 그 중에서도 또 선별해서 볼 수 있을 것 같아요.
		- objective detection같은 경우는 mask R-CNN부터 다른 모델들이 뻗어나갔죠. 그런 시작점과 줄기만 이해해도 충분해요. 거기서부터 시작해서 찾아보기 시작하면 돼요.
	- 선택과 집중이 항상 필요합니다. 내가 어떤것에 관심있는지/내가 풀려고 하는 문제에 필요한 것들이 뭔지/어떤 것이 좋을지에 대해 고민을 하고 찾아보면 몇개 안나와요.
		- 블랙박스로 되어있는 것들은 그냥 갖다쓰면되고, 화이트박스로 알아야하는 모델은 좀 더 자세히 뜯어봐야하고.
		- 그렇게 적용하다보면 됩니다.

- 학습을 하면서 들었던 생각이 모델을 만들때 end-to-end 구조로 점점 바뀌고 있다고 느꼈는데 최신 연구 동향이 데이터를 분석하여 어느정도 처리 후 모델을 학습하는 것 보다 end-to-end 구조로 모델을 학습하는 것을 더 선호하고 있나요?? 혹시 그렇다면 왜 그런지 이유와 CV 분야가 아닌 다른 분야에서도 end-to-end 구조를 선호하고 있는 것인지 알고 싶습니다.

	- 좋은 질문인것같아요. 저도 처음 연구할때는 end-to-end구조같은것 없었고 사람이 손으로 하던 것부터 시작했어요.
	- 근데 석사 끝날때 쯤 end-to-end가 좋은 것이다! 이러더라구요. 그 땐 왜그런지 몰랐죠.
	- 사람이 디자인하는 것을 보면, 반드시 간과하는게 생겨요. 일부러 간단하게 simplify하기도 하고.
		- 그러나 gradient descent는 여러분들이 디자인한 것(여러분의 머리)보다는 좀 더 잘맞는 방법을 잘 찾아내준다고 볼 수 있어요.
		- end-to-end로 만들어주면 사람이 직접 디자인한 것 보다는 더 나을 확률이 높다! 라는게 지금까지는 일반적인거죠.
		- 항상 그런건 아니고, trade-off가 있죠. conv layer도 사람이 디자인한거잖아요. 그래서 제약을 걸어주는거고.
			- 데이터가 많다면 conv layer같은 것도 그냥 사용하지 않고 그냥 알아서 찾아라! 하면 더 좋을수도 있어요.
			- 그러나 데이터가 부족하니까 그냥 conv layer를 사용해서 좀 더 효율적으로 할수 있게 사람의 아이디어를 개입시키는거죠.
	- end-to-end를 선호하는건 분야하고는 상관없어요.
		- 사람이 개입할거냐 말거냐?는 항상 trade off가 있어요. 데이터의 양이나 몇가지 다른 상황들을 봐가면서 고르는 거라고 생각합니다.

- 최근 발표된 Dall-E model은 이미지 생성에서 큰 성과를 보였고 vit등 다양한 트랜스포머 기반 모델이 등장하고 있는데 트랜스포머 구조가 CNN을 완전히 대체하게 될까요? 추가적으로 CNN와 비교하여 트랜스포머 구조가 가지는 장 단점에는 어떤 것이 있을까요?

	- 이건 예언을 해달라는 얘긴데…ㅎㅎㅎ
	- 사실 예언을 한다는것 자체가 전문가들 사이에서는 사이비처럼 보여서…ㅋㅋㅋ
	- 그렇지만 아까 설명했던 것처럼 데이터가 많다면 사실 transformer가 우세하지 않을까 합니다.
		- 예를 들어 최근에는 text를 이해하게 만드는 그런 transformer를 만들었는데, 영상을 이해하게 하는 전이학습, fine-tuning을 해봤더니 그게 어느정도 잘 되었다는 실험결과가 있어요.
		- 아직은 데이터가 없으면 transformer를 사용하기가 어렵기 때문에, 그런 부분에서는 다른 모델을 사용하겠죠.
		- 나중에가면 조금 더 데이터가 없어지더라도 transformer를 사용할 수 있는 방법들이 나오지 않을까… 하고 생각합니다.
	- (질문) 교수님이 생각하시는 데이터가 많다는 기준이 어느정도인지 알 수 있을까요?
		- 모델 파라미터가 데이터보다 많으면 overfitting problem이 생겨요.
		- 그 데이터의 양 기준은 문제마다 다릅니다.
	- (질문) 트랜스포머를 사용하려면 왜 데이터가 더 많아야하나요?
		- Conv layer를 쌓는 모델은 구조에 한계가 있어요. 그러나 transformer 구조는 그런 구조 제약이 별로 없습니다.
		- Conv block은 레고블럭 같은거라서, 몇번의 손길로도(적은 데이터로) 적당한 형태의 모델을 학습시킬 수 있어요.
		- Transformer는 진흙같은 거라서, 손길(데이터)를 많이 주어서 모양을 더 sharp하게 빚어줄 수 있어요.
		- (오늘의 명언) ***Transformer는 ⌜진흙⌟이다.\***

- 1. CycleGAN 처럼 비지도학습이 되면 데이터를 모을때 장점이 있는데, Computer Vision에서 또 다른 비지도학습 모델은 무엇이 있나요?

	- 얀 르쿤 교수님이 밀고있는 토픽이죠.
	- pretext task란 영상인식을 하게 만드는데, 그냥 영상인식을 하는게 아니라 이미지를 잘라서 무작위로 섞은다음 직소퍼즐을 풀도록 하는 task에요.
		- 완전 다른 task같지만, 이게 가능하다는 것은 결국 영상 내에서 물체들을 정확히 분류하고 인식하고 있다는 거거든요.
		- 이 pretext task를 사용하여 학습시키면 영상 관련된 task의 퍼포먼스를 훨씬 올릴수있지 않을까? 그게 하나의 연구 축이구요.
	- 또, 모션/3D 추정에서도 사용하고 있어요.
		- 이건 사람이 직접 하기가 거의 어렵거든요?
			- 이미지 한장을 판단해서 3D로 그려낸다? 이런 건 정답레이블을 만들기 어렵죠.
		- 그래서 이런것들을 그냥 self-supervised로 해결하려는 시도가 있어요.

- 자율주행 자동차에서는 단순히 detection이 아닌 물체의 다음 위치 예측도 중요한 이슈라고 생각되는데 이에 관련된 대표적인 방법론과 논문을 소개해주시면 감사하겠습니다.

	- 이건 먼저 3D 예측이 되어야돼요. 사람이 어떻게 움직이더라, 차들은 어떻게 움직이더라… 이런 history를 배워야하는데 이걸 배우는게 generative 모델이구요.
		- 그런 generative 모델로 예측을 하는게 forecasting, trajectory
	- 3D detection 쪽에서는 Frustum을 검색해보시는게 좋을 것 같아요.
	- 더 좋은논문 보는게 좋으니까 CVPR, ICCV, ECCV, NIPS, ICLR 등에서 좋은 논문들 검색해서 보세요.
	- 지금은 매주마다 양질의 많은 논문이 나와서, 지금 짚어주는건 의미가 없을것 같고 직접 찾아보시는게 더 도움될거라고 생각합니다.

- 현재 딥페이크는 주로 인물의 얼굴이나, 특정 부위를 합성하는 방식이 주를 이루고 있다고 들었습니다. 1. 좀 더 자연스러운 합성을 위해서 얼굴 등 지엽적인 부분에 그치지 않고 신체 전체를 합성하는 방법이 앞으로 등장할 수 있을 것 같습니다. 이에 대한 연구가 진행되고 있다면 현재 당면한 대표적인 어려움은 어떤 것인지 궁금합니다. 2. 딥페이크로 바꾸는 신체 부위 이외에 다른 부위가 자연스럽게 연결될 수 있게 고치는 과정에서 발생하는 컴퓨팅파워를 효율적으로 처리하는 대표적인 매커니즘에는 어떤 것이 있을까요?

	- 2번
		- 다음주에 컴퓨팅파워를 사용하는 방법을 배우므로, 이건 다음주에 배울 것 같습니다.
		- 2강에서 배웠던 knowledge distillation도 그런 것과 연관있는 방식이죠. student 모델은 더 경량화시키는 모델이니까.
	- 1번
		- 딥페이크가 전체 신체로 가면 pose transfer에요. 얼굴이 아니라 몸 전체를 바꾸어주는 겁니다.
		- pose transfer로 찾아보시면 되게 잘나오고, Liquid GAN이랑 imposter로 검색해보면 최근 ICCV 논문이 하나 나올텐데 그게 아주 매력적이에요. 한번 찾아보면 좋을것같습니다.
		- 대표적인 어려움은 카메라의 한계죠. 카메라는 멀리있는 사람은 축소되어 보이고 가까이 있는 사람은 커보이니까, 그건 근본적인 카메라의 한계죠. 3D 깊이 정보가 애초에 없으니까.
			- 영상 한장가지고 안풀리는 문제가 맞아요.
			- 물리적인 제약조건을 묻는것도 어렵죠. 사람에게 있을 수 없는 팔이 부러진 형태 같은 포즈를 우리는 바로 알 수 있지만, 이런건 모델은 잘 모르거든요. 그래서 엉뚱하게 인식하는 경우도 있죠.

- 기업에서 자율주행에 대해 연구개발을 진행할 때, 주행 데이터를 내부 시운전을 통해서도 수집할 수 있겠지만, 그것만으로는 부족할 것으로 생각되는데, 어떻게 데이터 수집을 하는지 궁금합니다. 또한 카메라 또는 Lidar를 통해 데이터를 수집한다면 데이터 크기가 상당할텐데, 여러 저장소에 흩어져 있다면 학습을 어떻게 수행하나요?

	- distributed learning, distributed training, 최근에는 federated learning같은 토픽도 있어요.
		- 기존에는 엣지 디바이스들의 데이터들을 서버로 모아서 학습하고 예측값을 엣지 디바이스들로 내보내죠.
			- 이 경우 내 민감한 프라이버시 데이터가 서버로 간다는 위험성이 있어요.
		- 그런데 내 기기에서 학습시키고, 모델 파라미터만 보내주면 그런 위험이 없겠죠? 그런 주제입니다.
	- 인문학적으로도 발전이 되고 있는것같아요. 딥페이크도 원래 위험하게 사용될 수 있는데, 좋게 사용하면 익명성을 강화하는데에 사용할수도 있잖아요.

- 영상을 처리하는 문제에 있어, 속도가 굉장히 중요할 것으로 생각되는데 python이 아닌 c언어의 비중이 어느정도 되는지 궁금합니다.

	- 제가 박사과정 할 무렵인 12~14년도쯤에는 C를 많이 사용했었어요. 근데 지금은 파이썬을 더 많이 쓰죠. 프로토타이핑이 빨라서.
	- 연구는 python으로 하고, 서비스는 빨라야하니까 python으로 작성된 걸 다시 C언어로 많이 작성을 하긴 합니다.
		- 근데 요새는 그렇게 하면 서비스 전환 속도가 너무 느리니까, 텐서플로우나 이런 프레임워크에서 파이썬 모델을 C로 컨버팅시켜주는 기술이 탑재되었어요.
		- 그니까 파이썬만 잘하면 됩니다.

- 3D data의 경우 2D data를 처리하는 것에 비해 더 많은 연산처리량이 필요할 것으로 예상되는데, 이를 real time에서 사용하기 위한 방법론이나 연구가 진행되고 있나요?

	- 3D는 2D에 비해 데이터가 sparse해요. 이걸 어떻게 효율적으로 multiplication할까도 topic이고,
	- 3D 데이터를 2D로 바꾸어서 연산하는것도 방법중의 하나예요.

- CV에서 현재 가장 주목 받고 있는 분야는 무엇인가요?(ex. self-supervised, 3D segmentation 등)

	- 주식 종목 찍어달라는거랑 비슷한것같은데 ㅋㅋㅋㅋㅋ
	- 개인적으로는 self-supervised learning도 유망한 분야지만, 그건 target task가 없어요. 그래서 그 자체보다는
		- 대량 데이터와 target task의 소량 데이터를 모두 이용하는 semi-supervised learning으로 가야하지 않을까 합니다.
	- 두번째로는 3D요.
		- 2017년쯤이나 되어서 3D 모델이 2D만큼 성능을 낼 수 있다는 결과들이 나오기 시작해서, 이제 활용처는 많은데 아직 연구는 많이 진척이 안된 상태에요. 그리고 사람들에게 직관적으로도 굉장히 매력적인 분야잖아요.
	- 세번쨰는 Generative model이죠.
		- 생성하는 것도 application할 곳이 많기 때문에 좋은 분야라고 생각합니다.

- GAN의 경량화는 어떻게 연구가 이루어지고 있나요? GAN에서도 여러가지 task가 있겠지만 사람의 머리 색을 바꾼다던가 스타일을 바꾸다던가 원본 영상이 없는 경우 정확도 측정은 어떻게 이루어 지나요?

	- 이건 정말 좋은 질문이네요. 이런 수준높은 질문이…
	- GAN 경량화는 일반 NN 경량화와 달라요. 일반 NN는 classification score가 조금 바뀌어도 결과는 같기때문에 구조의 몇몇 부분을 빼도 되는데, GAN은 최대한 실물과 비슷하게 만드는것이 목적이기 때문에 그렇게 하기가 어려워요. 설령 몇개 빼서 만든다고 해도 인간의 눈은 굉장히 sensitive하기 때문에 그 미묘한 이질감을 바로 catch하게 돼요.
	- Knowledge distillation 같은 방식을 많이 사용합니다. teacher-student 모델.
	- 정확도 측정은
		- 키워드 : Inceptation score, FID를 검색해보시면 됩니다.
		- pretrained된 모델을 사람 눈처럼 작동하도록 만들어놓고, 그걸 토대로 스코어를 측정합니다.
		- 근데 원본이 없으니까, 데이터 풀에서 가장 가까운 이미지를 찾고, 생성된 출력물과의 차이를 비교하여 점수를 매깁니다.
	- 이런거 다 가르쳐드리면 안되는데… ㅋㅋㅋ 스스로 찾아서 공부하셔야합니다.

## 캠퍼분들을 위해 드리는 말씀

과거에는 진입장벽이 높았어요. 오픈소스/프레임워크도 없었고, 현재처럼 치열하지 않았어요. 근데 지금은 bar가 낮아졌지만 job을 위한 경쟁은 더 치열해졌어요. 그러다보니 여러분들이 해야할 것은 선택과 집중을 하는 능력이라고 생각해요. 뭐가 중요하고 어떤 것에서 강점을 가질지.
그리고 제가 흐름을 말씀드렸잖아요. 연구의 역사적인 패턴들과 그걸 통해서 미래의 연구방향을 어느정도 예측할 수 있는 감, 그리고 이 모델이 이전 모델과 어떻게/왜 다른지를 이해하는 감이 중요해요.
항상 ***인생은 trade off***인데, 어느 것을 선택할 지 잘 고르기는 어려워서 멘토가 중요해요. 그렇지만 또 멘토를 구하기도 어렵잖아요. 그래서 우리는 간접경험을 많이 해야합니다. 논문, 아티클, 발표 등에서 레퍼런스를 많이 찾고, 그 레퍼런스에서 이 사람들은 어떻게 고민하고 결정했는지 왜 그렇게 했는지. 이런걸 찾아보면 도움이 많이 될 것 같아요.
마지막으로는 영어가 정말 중요하다. 이건 다들 하는 말이겠지만 영어를 알면 정말 좋아요. 국내 번역서중에 아무리 잘 된 것도 원문수준을 본적이 없어요. 영어로 된 자료들이 훨씬 더 많은 topic과 좋은 정보들을 담고있어요. 덕중의 덕은 양덕이라는 말이 있잖아요(ㅋㅋㅋ). 질문글도 영어 글을 보시구요, 책도 영어 책 보세요. 그러면 한국어만 사용함으로써 생기는 일종의 지식의 경계가 무너지게 돼요. 블로그도 이왕이면 영어 블로그 보시고. 그러면 좀 더 빠르게 지식을 흡수할 수 있고, 차별화 할 수 있어요.
한 주 동안 많은 것 배우셨고, 이 시간이 앞으로 여러분들이 AI 엔지니어로 자신감을 가지는데 도움이 되었다면 좋겠습니다.

Select a repo



오태현 마스터님 마스터 클래스

1. 못적었습니다.

2. 마스터 님께선 동기 부여를 중요하게 생각하시는것 같다. 어떤 계기로 공부를 해야겠다 생각하셨는지, 왜 해당 도메인을 선택하신 건지, 어떤 삻을 위해 교수님이 되셨는지 궁금합니다.

	추운 겨울에 바깥에서 일을 해보니 따뜻한 곳에서 일을 하겠다는 동기부여를 하였다.중고등학교 때는 게임을 좋아해서 프로그래밍 하기위해 컴퓨터공학부에 갔고, 이 때, 원리를 이해하고 싶은 욕구로 인해 공부를 열심히 하였는데, 아는게 많을수록 자신이 아는 것이 부끄럽다고 생각하는 시점이 있게 되었다. 이후 대학원과 박사과정에서 동료들과 연구하는 것이 재밌었다. 하지만 동료를 모으는 것이 힘들어서 연구와 제자를 양성할 수 있는 교수를 하게 되었다.

3. 강의에서 굉장히 다양한 논문들을 소개해주셨는데요. 강의를 준비하실 때 기대하셨던 학생들의 이해 수준은 어느정도였는지 궁금합니다.

	5일 간의 강의로 컴퓨터 비전의 모든 것을 이해하기는 힘들다. 그래서 컴퓨터 비전의 발전의 많은 모델 중에 중요하다고 생각하는 몇 개만 추출하였고, 분석하는 방법에 대해서 자세하게 알려주려고 했다. 즉, 컴퓨터 비전의 전반적인 흐름을 알려주려고 노력했다.예를 들어 코드를 보고 내가 아키텍쳐 다이어그램에서 어디를 보고 있는지 알 수 있는 정도면 될 것 같다. 즉, 코드를 보고 수정할 정도가 되면 좋다.

4.  CV 분야는 다른 딥러닝 분야보다 기술이 빨리 발전했기 때문에 높은 수준의 기술을 가진 사람들도 상대적으로 더 많을 것 같습니다. 현재 CV 분야의 회사나 대학원에서는 어느정도 수준의 구현 능력을 기대하는지 궁금합니다.

	우리나라 대기업이나 외국의 기업들도 생각하는 수준의 개발자가 많지 않다. 그렇기 때문에 교재난이도에서 조금 더 공부한 수준이면 경쟁력이 있을 것이라 생각한다. no cord, low cord같은 툴을 사용해서 아이디어를 보여주면 좋다. 웹, 서버 엔지니어보다 코딩을 잘 할 필요는 없다. 깔끔하고 꼼꼼한 코딩이 필요하다. 코딩이 못생기더라도 그것을 협업할 수 있게끔 코딩하는 것이 중요하다. 오히려 빠른 프로토타입핑 스킬을 갖추면 될 것 같다. 이번 과제를 잘 수행했고 그것을 수정할 수 있다면 높은 수준이라고 생각하면 될 것 같다.

5. 각 강의마다 다양한 모델들에 대해서 설명해주시는데 현재 제한된 시간내에 강의를 수강하는 수강생의 입장에서 각 모델들에 대한 이해를 어느정도 하는게 좋을까요?

	강의를 여러번 반복을 해서 들으면서 전체적인 구조와 원리를 짚고 넘어간다. 예를 들어 mask-R-CNN같은 대표적인 부분만 가지고 논문과 코드를 공부하면 좋을 것 같다. 선택과 집중이 필요하다. 어떤 것이 중요할지 우선순위를 매기를 것이 중요하다. 이것에 대해 필요한 것이 무엇이고 이 모델들이 무엇인지 알아야한다. 또한 블랙박스로 쓸지, 화이트박스로 쓸지에 따라 공부의 양이 달라진다.

6. 학습을 하면서 들었던 생각이 모델을 만들때 end-to-end 구조로 점점 바뀌고 있다고 느 꼈는데요. 최신 연구 동향이 데이터를 분석하여 어느정도 처리 후 모델을 학습하는 것 보다 end-to-end 구조로 모델을 학습하는 것을 더 선호하고 있을까요?

	되게 좋은 질문이다. 처음에 나도 end-to-end가 나왔을 때, 왜 하는지 몰랐다. 하지만 사람이 디자인을 하다보면 놓치는 부분이 항상 있기 때문에, gradient descent를 사용하여 end-to-end로 진행하면 사람보다 성능이 좋을 확률이 좋다. 그러나 데이터가 적은 분야라면 사람이 아이디어를 가지고 분석을 해야할 수도 있다. 즉, 데이터의 양에 따라 골라서 모델을 디자인하면 좋을 것 같다.

7. 최근 발표된 Dall-E-model은 이미지 생성에서 큰 성과를 보였고 vit등 다양한 트랜스포머 기반 모델이 등장하고 있는데 트랜스포머 구조가 CNN을 완전히 대체하게 될까요?

	의견을 말하기 조심스럽지만, 내 생각에는 데이터가 많아지면 transformer 쪽으로 갈 것 같다. 왜냐하면 최근에 text를 이해하게 만드는 transformer를 만들었는데, 영상이나 음성 쪽에서 이 transformer로 만든 것을 사용했는데 의미 있는 결과를 얻었다.

8. 데이터가 많다는 기준과 왜 데이터가 많아야 한가요?

	데이터가 부족하면 overfitting의 위험이 있다. transform을 사용하면 data가 많아야하는 이유는 convolution으로 데이터를 쌓으면 데이터의 한계가 있지만 transform은 data를 쌓는 한계가 좀 적기 때문에 데이터가 많아야한다.

9. CycleGAN 처럼 비지도학습이 되면 데이터를 모을때 장점이 있는데, Computer Vision에서 또 다른 비지도학습 모델은 무엇이 있나요?

	pretext task를 개발이 많이 되었고 이러한 경우를 사용하면 이미지, 영상관련된 task들의 성능을 향상시킬 수 있다. 모션, 3D추정, 영상인식은 사람이 하기 힘들다. 그래서 요즘 이러한 task는 비지도 학습으로 넘어가는 경우기 많다.

10. 자율 주행 자동차와 같은 AI 모델을 구현할 때, 입력으로 받은 2D 이미지에서 어떻게 보행자와의 거리 정보와 같은 3D 정보를 얻는지 궁금합니다.

	자율주행 task에서는 먼제 3d detection이 되어야하고 history를 배워야한다. 이런 generate model로 fore casting을 해준다(?). (keyword 참고. 3d detection, frustum, fore casting, triage(?))

11. 딥페이크로 바꾸는 신체 부위 이외에 다른 부위가 자연스럽게 연결될 수 있게 고치는 과정에서 발생하는 컴퓨팅파워를 효율적으로 처리하는 대표적인 매커니즘에는 어떤 것이 있을까요?

	컴퓨팅 파워를 효율적으로 처리하는 것에 대한 자세한 내용은 다음주에 배운다. 이 분야에 대한 최신 트렌드만 설명하면 얼굴을 변형시키는 것을 몸 전체로 가면 pose transfer라고 한다. Liquid GAN, imposter가 있다. 이런 것에서 어려운 점은 물리적인 제약조건을 넣는 것이다.

12. 자율주행을 하면 카메라 또는 Lidar를 통해 데이터를 수집한다면 데이터 크기가 상당할텐데 여러 저장소에 흩어져 있다면 학습을 어떻게 수행하나요? 

	이는 distribte learning을 트레이닝을 하게되는데 블랙박스로 찍은 데이터를 회사로 보내서 모델을 만드는 것인다., 최근에는 federated learning을 이용하여 모델을 만들어 모델만 보낸다. 이러면 개인정보를 지킬 수 있따.

13. 영상을 처리하는 문제에 있어, 속도가 굉장히 중요할 것으로 생각되는데 python이 아닌 c언어의 비중이 어느정도 되는지 궁금합니다.

	컴퓨터 공학부 때는 C언어를 사용한다. 지금 python을 사용한다. 이는 프로토타이핑이 빠르기 때문이다. 실제로 연구에서는 C언어로 쓰고는 있지만 서비스로 전환할 때, 시간이 오래걸린다. 그래서 최근에는 python을 C언어로 처리하는 툴들이 많다. 그렇기에 python만 잘해도 된다.

14. 3D data의 경우 2D data를 처리하는 것에 비해 더 많은 연산처리량이 필요할 것으로 예상되는데, 이를 real time에서 사용하기 위한 방법론이나 연구가 진행되고 있나요?

	3D 데이터를 2D로 바꿔서 연산처리량을 줄여서 계산한다.

15. CV에서 현재 가장 주목 받고 있는 분야는 무엇인가?

	self supervised learning은 target task가 없다. target을 정하고 분야를 정하는 것이 올바를 것 같다. 또 3D는 많은 가능성이 있고 재미있기 때문에 매력적인 분야이다. 또 하나 더 설명하면 Generate model도 좋은 분야라고 생각한다.

16. GAN의 경량화는 어떻게 연구가 이루어 지고 있나요?

	이거는 정말 좋은 질문이다. GAN경량화는 일반 NN과 다르다. 사람의 눈이 민감해서 GAN경량화가 힘들다. teacher와 student를 만들고 작은 애가 큰 teacher GAN을 따라오도록 만든다. 키워드로는 inception score, FID이다. 이는 사람의 눈으로 볼 때, 좋아보이느냐를 판단하는 것이다. 원본이 없기 때문에, 데이터 풀을 이용해서 가장가까운 데이터를 찾고 이것을 측정한다.

17. 캠퍼들에게 마지막으로 하고 싶은 말

	어깨가 무거워지는 질문이다. 과거에는 진입장벽이 낮아졌지만 경쟁률이 세졌다. 우리가 해야하는 것은 선택과 집중을 하는 능력이 필요하고, 역사적인 흐름을 통해 기존의 패턴파악과 앞으로의 패턴 예측을 할 수 있으면 베스트일 것 같다. 인생의 trade off를 잘 잡을 수 있도록 멘토를 구하는 것이 중요하다. 논문 혹은 책, 레퍼런스를 잘 찾아서 학습을 하면 효과가 좋을 것 같다. 또한 영어가 중요하기 때문에 원서보다 더 좋은 text를 본 적이 없기 때문에, 원서로 보고 해석하는 힘을 기르른 것이 좋다.

	