# (2강) 자연어의 전처리

인공지능에서 가장 중요한 **데이터**!! “Garbage in, garbage out” 이라는 말이 있습니다.

일반적으로 좋은 데이터를 학습해야 좋은 성능의 모델을 기대할 수 있습니다.

또한 데이터 전처리는 단순히 '정제' 의 개념이 아니라, 어떤 문제를 해결하겠다는 task 정의의 의미도 포함하고 있습니다! ☺️



## 자연어 전처리

**전처리**

- 원시 데이터를 기계 학습 모델이 학습하는데 적합하게 만드는 프로세스
- 학습에 사용될 데이터를 수집&가공하는 모든 프로세스를 말한다.



**왜필요할까?**

> Task의 성능을 가장 확실하게 올릴 수 있는 방법이다.

모델을 아무리 바꾸고, 튜닝하더라도, 데이터 자체가 문제라면 성능이 나오지 않는다. 



### 자연어 처리의 단계

1. TASK 설계 : 악성댓글 필터링해주세요~!
2. 필요 데이터 수집 : 댓글 데이터를 수집한다.
3. 통계학적인 분석
	1. 토큰 개수 확인 -> 아웃라이어 제거
	2. 빈도 확인 -> 사전 정의
4. 전처리
	1. 개행문자 제거 / 특수문자 제거 / 공백제거 / 등등...
5. tagging
6. tokenizing - 자연어를 어떤 단위로 살펴볼 것인다
	1. 어절 tokenizing
	2. 형태소 tokenizing
	3. wordpiece tokenizing
7. 모델 설계
8. 모델 구현
9. 성능평가
10. 완료

위 과정을 반복적으로 수행한다. 한번에 안끝남.



### Python string 관련 함수

```python
# 대소문자의 변환
upper() # 모두 대문자로 변환
lower() # 모두 소문자로 변환
capitalize() # 문자열의 첫 문자를 대문자로 변환
title() # 문자열에서 각 단어의 첫 문자를 대문자로 변환
swapcase() # 대문자와 소문자를 서로 변환

#편집, 치환
strip() # 좌우 공백 제어
rstrip() # 오른쪽 공백 제거
lstrip() # 왼쪽 공백 제거
replace(a,b) # a를 b로 치환

#분리 결합
split() # 공백으로 분리
split(''\t') # 탭을 기준으로 분리
'str'.join(s) # 리스트 s에 대하여 각 요소 사이에 공백을 두고 결합
lines.splitlines() # 라인 단위로 분리

#구성 문자열 판별
isdigit() # 숫자 여부 판별
isalpha() # 영어 알파벳 여부 판별
isalnum() # 숫자 혹은 영어 알파벳 여부 판별
islower() # 소문자 여부 판별
isupper() # 대문자 여부 판별
isspace() # 공백 문자 여부 판별
startswith('hi') # 문자열이 hi로 시작하는지 여부 파악
endswith('hi') # 문자열이 hi로 끝나는지 여부 파악
```



## 한국어 토큰화

토큰화(Tokenizing)

- 주어진 데이터를 토큰(Token)이라 불리는 단위로 나누는 작업
- 토큰이 되는 기준은 다를 수 있음(어절,F단어,F형태소,F음절,F자소 등)

문장 토큰화(Sentence+Tokenizing)

- 문장 분리

단어 토큰화(Word+Tokenizing)

- 구두점 분리,F단어 분리
- “Hello, World!”F->F“Hello”,F“,”,F“World”,F“!”



**한국어 토큰화**

- 영어는 New York과 같은 합성어 처리와 it’s와 같은 줄임말 예외처리만 하면,F띄어쓰기를 기준으로
	도 잘 동작하는 편
- 한국어는 조사나 어미를 붙여서 말을 만드는 교착어로,F띄어쓰기만으로는 부족
	- 예시) he / him $\rightarrow$ 그 , 그가 , 그는 , 그를 , 그에게
- 한국어에서는 어절이 의미를 가지는 최소 단위인 형태소로 분리
	- 예시)안녕하세요 $\rightarrow$ 안녕 / NNG, 하 / XSA, 세 / EP, 요 / EC







**실습 코드 링크**

- [0_한국어_전처리](https://drive.google.com/file/d/1MJ50R4ejf6LQImczKi-HPnoW9fQZ2hk8/view?usp=sharing)
- [1_한국어_토크나이징](https://drive.google.com/file/d/1AwabisXdZ2Xyewy0YttNthRczua4T6Dj/view?usp=sharing)

 

**Further Reading**

- [청와대 국민청원 데이터 전처리 (소개)](https://www.youtube.com/watch?v=9QW7QL8fvv0)
- [청와대 국민청원 데이터 전처리 (실습)](https://www.youtube.com/watch?v=HIcXyyzefYQ)

 

**Further Question**

- 텍스트 정제라는 것이 정말 필요할까요?
	- 어쩌라는거야? 싶으시죠? ☺️☺️
	- 실제로 우리가 웹이나 메신저를 통해 사용하는 언어는 '정제 되지 않은 언어' 입니다.
	- 해당 데이터가 적용되는 방향에 따라 정제가 필요할 수도, 필요하지 않을 수도 있습니다.
	- 오히려 더욱 어려운 데이터로 학습한 모델의 성능이 좋을 수도 있죠 ☺️

 