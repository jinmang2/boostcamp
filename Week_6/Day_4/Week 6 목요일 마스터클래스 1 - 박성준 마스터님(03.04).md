# Week 6 목요일 마스터클래스 1 - 박성준 마스터님(03.04)

Upstage Research Engineer

## 사전질문

- 요약이나 감정점수처럼 잘 했는지 평가하기 어려운 task들은 어떻게 평가하고, 더 잘 학습시킬 수 있을까요? 예를 들어 뉴스를 3줄 요약하거나 뉴스가 얼마나 긍정적/부정적인지 점수를 매겼을 때 어떤 것을 Ground Truth 로 봐야할지, 일반적으로 쓰이는 방법이 있는지 궁금합니다.
	- 요약이랑 감정에 대해서 말씀드리면
	- 요약은 대표적 자연어 생성 task
		- 요약 모델의 성능을 평가하는 지표가 따로 있습니다.(ROUGE 스코어?)
		- 요약도 크게 두 종류가 있는데
			- 문맥에서 대표적인 문장들을 추출하여 추출요약
			- 요약문을 생성하는 생성요약
			- 접근방법이 조금 다릅니다.
	- 감정도 여러 평가방법이 있는데
		- 감정은 문장 분류과제의 일환으로 보기도 합니다.
		- 여러 모델에 annotation을 시키고 어느정도 일치가 되는 것을 ground truth로 본다던지 하는 방법이 있습니다.
- 마스터님께서는 언어 모델을 활용한 프로젝트 중 가장 인상에 남는 것은 무엇인지, 언어 모델을 처음 사용해볼 때 추천하시는 태스크는 무엇인지 궁금합니다
	- 언어 모델은 아주 예전(00년대)부터 있던거라서 task가 새롭지 않을 수 있는데,
	- 최근에 나온 BERT를 기준으로 한다면 좀 성능 향상이 많이 되어서 해볼만한 task들은
		- 기계 독해같은 것들
		- 그 외에도 한 모델이 여러 task를 다 잘하게 되었습니다
	- 언어모델은 결국 task라고 생각합니다.
		- 어떤 input을 받고 어떤걸 output으로 내고, 그 파이프라인 전체를 보는것이 언어모델링이라고 생각해서,
		- 전반적인 파이프라인을 이해하면서 BERT를 써보기엔 제일 단순한 문장 분류가 좋지 않나 싶습니다.
		- 영어는 Sentiment?같은거나 한국어는 NSMC.
- 언어 모델 논문을 구현해볼때 여러 성능 평가 지표를 계산하여 논문의 기재된 수치와 비교해보면서 구현을 해야 된다고 생각이 드는데 이러한 평가 지표에 대해서도 추가적으로 공부해야 될까요??
	- 저는 굉장히 많이 추천합니다.
	- 요새는 좋은 언어모델이 많이 나오고, hugging face같은곳에서 쉽게 가져다 쓸 수 있다보니, 언어모델을 무엇을 쓰느냐는 쉬운 일이 되었습니다.
	- 그보다는 정확한 파이프라인을 이해하는 것이 중요한 것 같아요.
	- 문장분류같은건 F1 스코어 이런걸 보는데에 이견이없지만 새로운 task들은(기계독해, 목적형 대화 등)
		1. 어떤 평가지표를 사용할지도 어렵고
			- 목적형 대화같은경우에는 평가하는 방법도 연구하는사람들 사이에서 분분합니다.
		2. 평가지표 자체에 문제가 있는경우도 많습니다.
			- 단어단위로 span을 잡아야하느냐?같은 이슈들
	- 이런 디테일을 잡아두시면 좋을것같아요.
- 기계어 번역같은 잘 알려진 것 이외에 현업에서 사용되는 자연어 처리는 어떤 것들이 있는지 궁금합니다. 자연어 전처리 중 토큰화 과정에서 오픈 라이브러리(konlpy, mecab)를 적극 사용하시는지 아니면 데이터에 맞는 토크나이저를 따로 개발하시는지 궁금합니다.
	- 전 연구쪽에 치우친 사람이라 잘 모르긴 하지만…
	- 기계번역은 자연어 생성쪽 task다 보니까 오히려 난이도가 어려운 축에 속하는데
	- 난이도가 쉬운 측은 오히려 성능이 더 잘나오다 보니까 현업에서 사용하기 쉬운(좋은) 편이긴 합니다.
		- 인공지능 스피커 -> 목적형 대화
		- 현업에서 서비스 대화를 할때에는 모델 하나만 가지고 다 해야하니까
			- 전처리 -> 형태소분석
			- 후처리(원하지 않는것 거르기) -> 문장 분류
	- 나와있는 오픈 라이브러리를 쓰는게 편하긴 하지만, 특정 task를 더 잘하고싶다면 tokenizer부터 직접 디자인하는게 맞다고 생각합니다.
		- transformer를 사용한다면 BPE, sentence tokenizer같은걸 많이 쓰는데…
		- 최근 카카오브레인과 스켈터랩 공동연구에서는 mecab같은걸로 한번 처리 한뒤에 (이후는 못들었습니다)
- 과거의 데이터가 주어졌을 때 사람의 불확실한 행동과 심리를 AI로 예측하는 것이 가능할까요? (포커, 스포츠 등) 자연어 처리를 할 때 반언어적 표현을 고려하는 방법에는 어떤 것이 좋을까요? 법 - 학습용 데이터를 편하게 얻을 수 있는 사이트나 방법 같은게 있으시나요?
	- 사람의 심리 예측은 어렵긴 하겠죠? ㅎㅎ
	- 결국은 AI가 마법이 아니라 패턴 예측인건데, 사람의 패턴이라는게 있다면 충분한 데이터가 있으면 학습해서 패턴을 예측할수는 있습니다. 심리를 예측한다기보다는 패턴 예측에 좀더 가까운것같아요.
	- 개인적으로는 그렇게 생각합니다.
	- 반어법같은거라면
		- 이건 좀 어려운것같아요.
		- 비꼬는듯한 sarcasm은 NLP에서 아주 처리하기 어려운 문제로 알려져있습니다.
		- 비속어라면 비속어를 고려하는 것 자체가 큰 이슈라서…
			- 아직 이 부분은 연구의 영역에 속해있는 것 같습니다.
	- 비언어적 표현이라면
		- 저는 개인적으로는 음성이나 비디오데이터를 같이 합쳐 고려해야한다고 생각합니다.
		- 멀티모델 방향으로 가야하지않을까?
		- 연구를 앞서가시는 분들은 시각정보와 언어모델을 같이 개발하시는 분도 계십니다.
	- 사이트라면
		- AI Hub
		- 논문 저자가 직접 공개한 데이터 -> Git Hub
		- 목적에 따라 다른거같아요.
			- 연구를 할거라면 남들이 만든 데이터를 쓰는게 편한데요.
			- 내가 정말 어떤 시나리오의 문제를 잘 해결하고싶다면
				- 보통 데이터 자체를 새로 만드는게 더 좋은 방법이었던것같아요.
				- 더 좋은 방법이 있으면 저도 알려주세요 ㅎㅎ
- 전산심리학에 대해서 소개해주세요, 그리고 실제로 필드에 활용될 수 있을지에 대해서 의견을 들려주세요. 심리학과 인공지능을 결합시키겠다(?)하게 된 계기가 무엇인지 궁금합니다.
	- 계기
		- 학부부터 컴퓨터공학을 전공하지 않다가, 살다보니 중간에 관심이 생겨서 30살에 박사를 시작했어요.
	- 현실적인것부터 말씀 드리면,
		- 나보다 훨씬 오래전부터 잘하고 좋은 성과를 내시는 분들이 너무 많은것같아요.
		- 그런데 저사람들보다 내가 잘해야지 하는 목적을 잡으면 자기자신을 힘들게 하는 것같아요.
	- 이전에 공부했던 심리학은
		- 재미는 있었지만, 뭔가 데이터를 기반으로 예측을 하는 학문은 아니다 보니까
		- 컴퓨터기반의 방법론, 특히 AI를 적용하면 실질적인 프로덕트를 만드는데 기여할 수 있지 않을까? 하고 생각했었습니다.
	- 컴공이 아닌 분야에서
		- (뭔가를 공부하고싶다는) 내적인 모티베이션을 공부하고자 하는 분야에 결합하면 좋지않을까 합니다.
	- 전산심리학 자체는
		- 컴퓨터 공학론적 방법을 이용해서 감정을 연구하는 것에 가까운것같습니다.
		- 필드에 활용될 수 있을것 같은데, 기계를 이용해서 감정을 추출하는 영역이라고 생각하고있어요.
		- 일반인들을 대상으로 하는 self-care나 멘탈 헬스 케어같은것도 기본적인 감정 분석 모듈이 필요한데 이런 부분을 기계가 도와줄 수 있지 않을까 합니다.(감정예측, 감정분석)
- 다국어 벤치마크를 이용해서 프랑스어(FLUE) ↔ 한국어(KLUE) 간의 번역 모델을 만들때 각각 FLUE에서 가장 좋은 벤치마크 성능을 내는 모델1와 KLUE에서 가장 좋은 성능을 내는 모델2를 선택해서 모델링 하는지가 궁금합니다. 예를 들어, 기계번역 프로젝트를 하는 팀이 있다면 조직 안에 다양한 언어를 담당하는 비개발자 인력이 언어마다 존재하나요? 또, 영어/한국어 이외의 NLP 프로젝트를 하려면 엔지니어의 제 2외국어에 대한 이해가 얼마나 필요한지도 궁금합니다.
	- FLUE나 KLUE같은 경우는 번역 벤치마크라기보다는 언어 성능을 평가하기 위한 task들의 모음집이라고 보셔야 할 것 같아요.
		- 완전히 동일한 task로 구성되어있지 않고, 그렇다고 하더라도 1:1로 번역된 페어가 아니라서
		- 그렇게 하기는 어렵지 않을까 생각합니다.
	- 한국어 이해를 잘하는 모델이 있지 않을까 생각하는데,
		- 어떤 걸 하고싶느냐에 따라 특정 언어에 좋은 모델을 사용하는게 맞겠죠.
		- 둘다 잘하고싶다면 multilingual 모델이 생각보다 많이 공개되어있어요.
			- 페이스북이 여기에 관심이 많은데, 작년에 발표한? XLM이라는 다언어모델이 있는데, 대충학습한 한국어 언어 모델보다 더 성능이 좋습니다.
	- 번역 모델을 잘하고싶다는 걸 놓고 보면
		- 생성 모델 쪽에서도 multilingual BERT라는 모델이 하나가 있고,
		- 구글에서도 multilingual T5같은것들을 갖다 쓰시는게 각각 언어에서 1등한 모델을 쓰는것보다 더 편할 것 같아요.
	- 조직안에 언어 담당 인력이 따로 존재하는지는
		- 기본적으로 transformer기반으로 자연어 처리를 하는 것 자체가 언어학적 지식을 덜쓰면서 불확실한 부분은 모델의 성능에 기대겠다는 의도가 깔려있어요.
		- 그래서 최대한 언어담당 인력을 줄이고싶어하는 느낌을 받은적 있습니다(구글에서)
			- 언어 사용자 수로 언어를 티어를 나누어서, 사용자가 많은 것들 위주로 serving하는게 아닌가…
		- 언어학자들이 필요하고, 실제로 팀에 있기는 합니다. 어찌됐든 input output을 비교해야하고…
	- 그렇지만 한국어 이외의 자연어 프로젝트를 하려면, 엔지니어로서 언어 자체에 대한 이해가 필요하다고 생각합니다.
		- 잘 모르면서 언어를 serving하기가 어렵고…
		- 그래서 기계번역이 어려운거같아요. 사람도 3-4개씩 언어를 잘 하는게 어려우니까…
		- 다국어 번역/다국어 벤치마크를 다 잘하려면, 그 사람도 여러 언어를 다 잘해야하는게 아닌가? 하고 생각하기도 합니다.
	- (질문) 그럼 비슷한 언어 족이면 다국어 번역같은게 더 잘 작동하나요? 영어-독일어 vs 영어-중국어
		- 네 맞습니다.
		- 언어학적으로 비슷한 그룹으로 묶이거나, 비슷한 체계를 가진 언어들은 훨씬 성능이 좋게 나옵니다.
- 블로그를 살펴보니 글을 정갈하게 잘 쓰신다는 느낌을 받았습니다. 논문을 쓰거나 현업에서 일하며 문서화를 하는 등 글을 잘 쓰는 것이 중요하다고 생각하는데 마스터님 만의 글 잘쓰는 팁 있을까요?
	- 글 쓰게 된 동기는
		- CS 쪽 논문들이 8페이지밖에 안되는데, 프로젝트 내부의 것들을 8페이지에 다 넣기가 힘들어요.
		- 그래서 아쉬운대로 이걸 기록으로 남겨보자 싶어서 시작했어요.
	- 저는 글쓰기도 되게 중요하다고 생각해서 트레이닝을 많이 받아야하는것같아요.
		- 학회쪽으로 관심 있으신 분은 논문 글쓰기같은 경우는 대학원에서 트레이닝을 받는게 좋지 않나 합니다.
		- 현업에서 일하면서 문서화도 되게 중요한 것 같습니다.
	- 글 잘쓰는 팁이라고 하면
		- 어떤 생각을 가지고 일을 하면, 그때 무슨 생각을 가지고 일을 했었지 라는걸 잊기 전에 기록해두는게 중요한 것 같구요.
		- 말하고싶은 내용들을 주제로 잡아서 개조식으로 작성을 한다음, 정리가 된 문서를 보면서 사람이 읽기 쉬운 형태로 포맷팅을 다시 하는 편입니다.
			- 저는 감성적 글쓰기보다는 정보전달 글쓰기를 많이 하니까… ㅎㅎ 그런것 같아요.
- 영어->한국어, 프랑스어->독일어 등 번역 task 목적으로 설계한 모델은 수업이나 학습을 통해 숙지했는데, 파파고와 같은 다국 번역에 대해서는 어떤 모델 아키텍쳐가 구성될 수 있나요? 막연하게 상상하면 앞서 언급한 두 언어 간 번역에 비해 다대다 번역을 위한 복합적인 학습방법을 요구하고, 그에 따라 특정 언어 관계에 맞는 rule을 학습하기 위해 별도의 attention task들이 다양하게 존재해야 할 듯 싶습니다. 사실, 개인적으로 한국어 데이터로만 공부 및 연습하게 되면, 자연어 처리 도메인에 대해서 다소 가성비가 좋지 않은 공부법이 될 것 같아 걱정됩니다.
	- 예시가 파파고가 나와서 어떻게 대답해야될지… 근데 오후에 파파고 개발하신 분(문지형 마스터님)이 나오셔서 그분께 여쭤보시면 좋을 것 같아요.
	- 한국어 데이터로만 연습하면 가성비가 좋지않은 공부일 수 있죠. 그럴 수 있는데…
		- 특정 언어를 잘 다루고 싶으시면 언어에 좀 더 specific한 모델을 보시면 될 것 같은데,
		- 일반적인 머신러닝 모델에 대한 관심이 많으시면 한국어 자료가 적으니까 영어쪽 모델을 좀 더 보시는게 좋을것같고,
		- 국내에서 한국어 관련된 문제를 잘 풀고싶으면 한국어 모델 공부가 그렇게 가성비가 나쁘지는 않다고 생각합니다.
- 어떤 기회를 통해 3개 회사(네이버 클로바, 카카오 브레인, 구글 리서치)에 인턴을 할 수 있었는지와 이에 대한 동기, 각 회사에 대한 느낀점이 궁금합니다. 구글 같은 실리콘밸리 AI 팀과 국내 기업의 AI 팀을 경험하시면서 느낀 차이를 간략하게 말씀해주실 수 있나요?
	- 클로바는 활석님이 배려를 많이 해주셨고 ㅎㅎ 카카오 브레인은 논문을 쓰다보니 규병님과 같이 일했었고, 구글 리서치는 좀 복잡한 절차를 거쳐서 리서치 인턴을 했었고…
	- 이건 너무 제케이스에 오버피팅 되다 보니…
		- 이건 사람마다 다 다른 것 같아요. 리서치 인턴을 하는 '방법’같은건 없다고 생각합니다.
		- 무엇을 하고싶은지 따라 다른것같아요.
		- 굳이 리서치 인턴이 아니더라도, job description을 잘 보시고 그냥 지원하시면 절차대로 들어가는것같아요.
			- 리서치 인턴은 논문을 구현하고, 면접을 한두번 더 보고 이런식으로 진행됩니다.
	- 일반적인 방법이라기보다는, 어떤 회사의 어떤 인턴을 하고싶다 라는걸 좁혀놓고, 그걸 하려면 어떤걸 준비해야하는지 리스트 짜놓고 실제로 해보신 분들한테 여쭤보는게 좋을것같아요.
	- 하게 된 동기는,
		- 논문들이 회사에서는 어떤 의미가 있는지 궁금했어요.
		- 회사 생활을 오래 한건 전혀 아니지만, 잠깐이라도 회사에서 논문을 가지고 어떤 일을 하는구나를 경험해보고싶어서.
	- 각 회사에서 느낀건
		- 조심스러운데 ㅎㅎ
		- 분위기가 많이 다릅니다.
		- 차이가 많이 두드러지는 것은, 네이버 카카오같은 경우는 완전 연구목적 조직보다는 연구+서비스였지만, 구글은 리서치 조직이 방대했고 제가 했던 파트는 완전히 연구파트였어요.
			- 국내 기업은 서비스를 위한 연구를 상대적으로 더 선호했어요.
			- 구글에서 제가 했던 부분은 거의 연구실이랑 비슷했어요. 다만, 한명한명의 연구자들이 다 박사학위가 있다?
				- 그래서 모든 사람들이 각자 NLP 주제 하나씩을 drive해나가는 느낌?
		- 또 연구 인프라/리소스 차이가 좀 있죠.
			- 구글은 리서치 인턴으로만 가도 TPU를 거의 제한없이 사용할 수 있어요…
			- 또, 최근에 어떤 논문을 만들었던 분들과 바로바로 이야기할 수 있으니까… 인적 물적 인프라가 차이가 있어요.
		- 다만, 구글 리서치같은 경우에는 너무 순수 연구를 하다 보니까
			- 실제로 이게 어디에 쓰는지는 감이 안와요.
			- 또 웬만한 주제로는 만족이 안오고, 24시간 자체를 NLP에 바쳐야 살아남을 수 있는 느낌이었어요…좀 부담이 될 수 있을것같네요.
- 첫 직장을 스타트업으로 결정하여 커리어를 시작하신 특별한 이유 혹은 계기가 있으실까요? (빅테크기업에서 3번 인턴 경험을 하셨는데, 영향을 끼쳤을 것으로 예상됩니다!)
	- 스타트업에서 일하기 위해서 업스테이지에 조인했다기보다는, 업스테이지에 너무 좋은 사람들이 많아서 배울 게 많겠다는 생각으로 합류하게 된 것 같아요.
	- 빅테크기업에서 인턴을 3번했던것이 저한테 준 경험은
		- 구글 리서치는… 꿈의 직장이긴 하죠. 그렇긴 한데
		- 구글 뿐만 아니라 다양한 인턴을 하면서, 박사를 졸업하는 시점에 내가 정말 하고싶은게 뭔가?를 고민하게 되더라구요
			- 유명한 논문을 쓰는 건가?
			- 큰 회사에 기대어서 커다란 조직의 방향성을 따라가는건가?
				- 그것에 반하는 일을 내가 할 수 있을까?
		- 그래서 그것보다 상대적으로 자유로운 스타트업을 가면 좀 더 좋을것같다는 생각이 들었습니다.
- NER 같은 task는 각 도메인마다 고유명사들의 분류가 상이할 것 같은데, (예: “배달의 민족” 이라는 [앱명], “카카오” 라는 [식물명] / [회사명]) 어떻게 general model을 domain specific하게 fine tuning 시킬 수 있나요?
	- 가장 좋은 방법은, domain specific한 데이터가 충분히 많으면 되는데요…ㅋㅋㅋㅋㅋ
		- 그런 일은 사실 없죠…
		- 보통 직접 다만들어야 하는 케이스가 많죠.
	- 어떻게 하면 모델을 좀 더 잘 개발할까보다는 요새 느낌이 극단적으로 모델의 크기와 데이터를 크게 키워서 사전학습시키는 분위기가 강하잖아요?(GPT-3)
		- 보통은 general한 모델을 하나 잘 만들고
		- 그다음에 특정 도메인에 맞게 tuning을 시키는것.
	- 저도 말씀하신 그런 방식들을 찾고있긴 한데,
		- 현실은 그냥 데이터가 짱이 아닐까 생각합니다.
- 예전에는 수학적인 원리를 사용해 문제를 해결하는 경향이 있었는데, 현재는 많은 parameter를 사용한 fine-tuning으로 성능을 향상시키는 경향인 것 같습니다. 이런 fine-tuning 경향에서는 연구 자본이 중요할 것 같은데 연구자의 관점에서 어떻게 생각하시는지 궁금합니다.
	- 구글리서치인턴과 엮이는 이야기같은데, 이래서 스타트업에 온것도 있는 것 같아요.
	- 사실 원리 규명보다 모델사이즈랑 데이터 늘리는게 더 잘되니까.
	- GPT-3같은 학습 한 번 하는데 몇십억 들어가는 모델을 보면…
		- 큰 모델을 학계에서 연구하는건 불가능하겠구나! 라는 생각이 들기도하고
		- 카카오나 네이버에서도 굉장히 ‘큰’ 의사결정을 해야 GPT-3같은걸 만들 수 있을 것 같아요.
	- 빅테크기업들의 연구를 그냥 가져와 쓰거나,
		- 그렇게 크지 못하더라도 충분히 유의미한 서비스를 만들 수 있는 방법을 찾아야 한다고 생각해요.
		- 특히 그런것과 관련해서 AI윤리가 정말 중요하다고 생각해요.
			- 학교나 작은 팀에서 할 수 있는게 뭘까?
			- 실제로 서비스 개발들이 어떻게 해야할까?
		- 그런 부분을 전략적으로 잘 파고드는게 중요하지 않나 싶어요.
- P스테이지의 두번째 스테이지에 KLUE 태스크가 있는 것으로 봤는데, 어떤 것을 하게 되는지 좀더 구체적으로 알 수 있을까요? 오늘 강의에서 다루어주신 KLUE 벤치마크 과제를 일괄 수행하는 것인지 궁금합니다!
	- 이건 김성현 강사님이 더 잘 설명해줄 것 같지만,
	- KLUE자체만 놓고 보면 8가지 정도가 있는데, 그중 난이도 있는 task가 기계독해와 목적형 분류
		- 각각 교수님과 마스터님(?)이 강의해주실겁니다.
	- 넓게 이야기하면
		- 한국어 모델을 어떻게 평가할 수 있고, 평가 데이터는 어떻게 만들어지고, 다양한 task를 어떻게 모델링 할수 있는지.
		- 김성현 강사님이 디테일을 고민하고 계세요.
- 질문이 있는데 zero shot setting은 거대한 텍스트 데이터로 기학습된 모델을 활용하여 fine tuning을 하지 않은 상태에서 downstream task를 수행하는 건가요 ?
	- 네 맞습니다.
	- 보통은 추가적 학습을 안한 상태에서 모델을 만져서 다른 task를 얼마나 하는지를 보는걸 zero shot이라고 하는데…
	- zero-shot은 새로운 example을 하나도 안넣는거고, few-shot은 example은 너댓개만 보고도 잘할 수 있는지.
		- 사실 성능 비교를 위해 애매하게 섞여 나오는 경우가 많아서… 좀 말씀드리기 애매합니다.
	- 학습을 한다/안한다 여부는
		- 2-3개만 가지고 파라미터를 아주 조금더 학습할수도 있고, 또는 GPT-3같이 유사한 사례들을 inference를 더 잘해보자! 처럼 될수도 있어요.
		- 이건 context가 좀더 디테일해야할것같습니다.

## 캠퍼분들께 마지막으로 하는 말씀

컴퓨터공학 공부 안했는데, 이제와서 해도 되나?라는걸 물어보시는 질문들이 많았던 것 같아요. 그 대답에 대해서는 언제나 '그렇다’라고 대답하고싶습니다.
단순히 코딩을 잘하는 것도 중요한데, 그것보다 자기가 다른 분야에서 쌓아왔던 전문성이 AI를 발달시키는 데에 큰 도움이 될 수 있습니다.
커리어를 쌓아나가기 나름이라서, AI/ML을 배우는데 늦은 시기는 없고, 본인의 우위를 잘 파악하고 발전시키는 것이 좀더 생산적인 일입니다.
그리고 이걸 공부한다고 해서 최고 권위자가 되어야한다는 생각은 가지지 않았으면 좋겠어요. 그냥 이런걸 공부하면서 세상의 다른 부분에 대해 알게되는것도 있잖아요. 기획자로서의 재능을 발견할수도 있고, 개발자로서 새로운 알고리즘을 발견할 수도 있고…
요새처럼 AI가 주목받는 세상에서는 사실 어떤식으로든 이걸로 공부하는 것이 도움이되니까요.

- Week 6 목요일 마스터클래스 1 - 박성준 마스터님(03.04)
	- [사전질문](https://hackmd.io/c9gBaMZqSmO6AsAn-QENjA?view#사전질문)
	- [캠퍼분들께 마지막으로 하는 말씀](https://hackmd.io/c9gBaMZqSmO6AsAn-QENjA?view#캠퍼분들께-마지막으로-하는-말씀)

