# Week 6 수요일 마스터클래스 1 - 김상훈 마스터님(03.03)

Upstage AI Challenge Director 캐글 세계 랭킹 최고 12위

## 사전질문

- 캐글과 실제 현업의 갭은 어느 정도 인가요? 캐글에서 필요한 역량이 실제 현업에서는 어느 정도의 비율을 차지하는지, 캐글에서는 예전 기술이 더 퍼포먼스가 좋은 경우도 있는데 꼭 최신 기술을 사용해야 하는지 궁금합니다.
	- (제 생각에) AI 모델링에 있어서는 거의 없다고 생각합니다.
		- 카카오 아레나라고 하는 국내 대회에서 우승한 적이 있었는데, 그 우승 기술을 그대로 현업에 갖다 썼습니다.
		- 카카오 아레나에서 풀려고 했던 ML 문제와 제가 풀려고 했던 현업의 문제가 거의 동일했기 때문에.
	- 캐글을 하다보면 경쟁이 엄청 치열한데, 이런걸 경험하다보면 현업에서의 모델링이 너무 쉬워집니다
	- 그렇지만, 서비스 전체를 다 차지하는 건 아니니까.
		- 네이버 OCR이나 파파고를 써보셨을 때, 성능이 좋지 않다 -> 단순히 모델링만의 문제가 아닙니다.
		- 적을때는 20% 많을때는 80~90%
		- 어떤 문제는 모델링 성능이 정말 중요하다.
	- 경험상 캐글같은 딥러닝 대회(이미지나 텍스트를 입력으로 쓰는)는 최신 기술이 일반적으로 더 좋습니다.
		- 논문에서 갓나온 따끈따끈한 모델이 아니라, Pretrained 모델이 있는 최신 기술
		- (경험) 대회 종료 일주일 전에 나왔던 트랜스포머 기반 XLNet을 사용했기 때문에 구글에서 개최한 대회에서 2등한 경험이 있음.
		- 앞으로는 대부분 최신기술이 캐글에서 쓰이지 않을까 생각합니다.
- 앙상블의 성능이 잘 나오는 이유로 대수의 법칙이 있다고 최근에 배웠는데 실제로 앙상블을 사용할 때 성능이 상대적으로 좋지 않은 모델들도 같이 사용하는지 궁금합니다. 좋은 모델만 사용해서 앙상블을 하는지 아니면 모든 모델만 사용해서 앙상블을 하는지 궁금합니다.
	- 제 경험상 성능이 좋지 않은 모델을 섞으면, 좋은 성능의 모델 점수를 깎아먹습니다.
	- 다만, 성능이 좋지 않은 모델을 앙상블하면 도움이 되는 경우가 있는데, 그건 어떤 경우냐면…
		- 다른 모델과 아키텍쳐가 아주 다를경우 섞으면 성능이 올라갑니다.
		- 이런 예외적인 경우를 제외하고는 성능 좋은 것들끼리 앙상블하는 편입니다.
	- 팀을 맺을 때, 본인과 비슷한 점수를 가진 사람과 팀을 하는 이유는
		- 적어도 나랑 비슷한 싱글모델을 가진 사람들과 앙상블해야 점수가 더 올라가기 때문에.
- 아직 새로운 모델을 짜는것에 어려움이 있어 dacon이나 kaggle에서 다른사람들이 만든 notebook을 따라 치면서 모르는 함수나 코드들을 공부하는 방식으로 하고있는데 이렇게 해도 좋은지 마스터님 께서는 처음에 도전을 하실떄 어떻게 공부를 하셨었는지 궁금합니다!
	- 좋은 방법인 것 같아요.
	- 저도 ML을 오래 한 편인데 (15년전) 얼굴인식기를 만들기 위해 잘되어있는 ML 오픈소스를 보고 따라쳤던 경험이 있어요.
	- 보는 순간 ‘멋진 코드다’ 느낌이 드는 코드들이 있습니다. 따라하면서 코드를 이해하시고, 자신만의 베이스 코드를 만드시는게 좋아요.
- 기존에 알고있던 도메인 지식이 어느정도 도움이 되나요? 또한, 후자일 경우 도메인을 어느정도 수준까지(ex. 데이터의 기본적인 내용만 이해하는 수준?) , 어떤 방법(ex. 해당 도메인을 잘 아는 동료를 구한다. )으로 학습하시려고 하는지 궁금합니다.
	- 어떤 도메인지식을 말씀하시는건지는 모르겠네요
	- 의료 경진대회같은 경진 대회에 대한 도메인지식이라면
		- 저는 도메인 지식 전혀 없이 나가는 편이에요.
		- 분자특성예측/백신개발/신약개발 -> 아무것도 모르고 나갔는데 금메달 딴 적 있어요.
		- 캐글이 세 달 정도 진행되어서, 내가 아무것도 몰라도 discussion에서 누군가가 정보를 정리해서 올려주는 경우가 많습니다.
		- 기존 캐글의 고인물들(나이들어보이는 프로필 이미지를 찾으세요) 보시면 ML은 잘하시는데 도메인지식은 없으시고, 점수이 높으세요.
- 경진대회의 경우 상위권 팀들의 사용 모델이 비슷하고 점수차이도 얼마 나지 않을 것으로 생각되는데, 막연히 "모델의 성능을 높인다"기보다 경진대회에서 극한으로 점수를 쥐어짜서(?) 높은 스코어를 받을 수 있는 팁이나 영업 비밀이 있을까요?
	- 상위권 팀의 점수차이가 얼마나지 않은 이유중 하나는
		1. 경진대회 문제가 쉬운 경우가 많음
		2. 이전에 레퍼런스로 참고할만한 상위권의 공개된 코드들 때문에 상향평준화 되어서
	- 대회에서 상위 1~50위는 자신만의 무언가가 없으면 힘들어요.
		- 그 '무언가’는 대회마다 다 달라요.
	- 그러나 은메달 정도까지(상위 50등 가까이)는 몇가지 팁이 있어요.
		- 앙상블
		- 학습데이터
			- unlabel된 데이터를 내 모델로 가짜 레이블을 붙여서 다시 학습에 사용
			- 그러면 점수가 조금 올라갑니다.
	- 높은 스코어의 모델을 잘 가져와서 하이퍼파라미터를 잘 조정한뒤
		- 앙상블과 학습데이터 레이블링을 해서 잘 조정해보시면 점수를 더 올릴 수 있습니다.
	- discussion 탭을 참고하면서 상위 랭커분들의 기존 코드 이력들을 다 확인해서 털어보시면 도움이 됩니다.
- 케글에는 다양한 주제들이 있는데 마스터님은 알고있는 도메인을 선택해서 참가 하시는지 아니면 잘 모르는 도메인이라고 할지라도 일단 참가해서 새롭게 공부하면서 도전하시는지 캐글 그랜드마스터님의 경험이 궁금합니다
	- 아까 도메인 질문에서 말씀드렸던것 같긴 한데, 잘 모르는 도메인도 흥미에 따라 많이 도전합니다.
	- 다만 이건 있어요.
		- 모르는 도메인에서 transformer를 적용해 볼수는 있는데, 그러려면 transformer부터 이해해야됩니다.
		- 근데 transformer는 NLP에서 나온거니까, NLP분야에서 먼저 적용을 해보긴 합니다.
		- 그러고 나서는 다른곳에 적용을 해보기도 합니다.
- 여태까지 마스터클래스에서 캐글 대회 참여를 추천해주시고 중요성을 강조해주셨는데, 학생이나 취준생 개인이 부담하기에는 GPU 가격이 매우 부담되는 것 같습니다. 캐글 대회 참여를 위해 이런 장비문제를 어떻게 해결해야 할까요?
	- 어려운 문제인데…
	- 구글 코랩 프로를 쓰면 가끔 V100 GPU(1000만원 상당)를 할당해줍니다. 그걸 참고하시면 좋을 것 같고.
	- 최근 Riiid 경진대회에서 구글 코랩 프로 여러개만을 가지고 1등하셨대요.
		- 1등하셨던 코드 공유가 가능하시겠냐고 여쭤봤더니 공개는 다음에 하시는걸로… ㅎㅎ
		- 데이터 로딩 자체가 좀 느리긴 해요 코랩은.
	- 캐글 노트북도 활용하시면 좋을 것 같습니다.
- 캐글을 빠르게 익히기위한 로드맵 같은게 있나요? 제일 처음은 타이타닉으로 입문을 하고 그 다음은 어떤competition을 해보고 능숙해지면 본인이 하고 싶은 대회를 참여하는 등등 이러한 추천해주실만한 로드맵이 있는지 궁금합니다.
	- 본인 흥미에 따라 여러 분야에 적용시킬 수 있을텐데
	- 대회별로 notebook이나 discussion 탭도 있지만, 전체 통합된 notebook과 discussion 탭도 있습니다.
		- 거기서 most voted 순으로 보시면서 참여하시는것도 좋구요.
	- 어떤 경진대회에 참여하면 좋냐?
		- 많은 사람들이 참여한 곳에 참여하는걸 추천드립니다.
		- 200명이 참여한 경진대회 vs 5000명 참여한 경진대회
			- 보통 적게 참여한 경진대회는 학습데이터가 엄청 커요(ex-500GB)
				- 돌리기 어려운 이런 데이터는 공유도 적어요.
			- Object detection같은 어려운 task들이에요.
			- 많이 참여하는 대회는 보통 좀 더 쉽고, 본인 코드와 아이디어를 공유하려고 하시는 분들이 많아서 참고해서 공부할 만한게 많아요.
- 캐글에서 팀별로 competition할 때 업무 분담을 어떻게 하나요? 모델 하나씩 맡아서 앙상블을 하나요? 마스터님의 노하우가 궁금합니다.
	- 팀이 중요한데, 조를 짜다보면 누군가는 열심히 하고 누군가는 프리라이더가 있죠? ㅎㅎ
		- 그래도 경진대회를 한번 시작하면 팀을 폭파할수가 없어요.
	- 그러면 기분이 나쁘잖아요. 저도 그런 사람때문에 학을 뗀 적이 있는데
		- 그래서 높은 점수에 있는 사람하고만 팀을 맺어요(적어도 저랑 비슷한 사람)
			- 왜냐하면 그런사람들은 그 점수가 아까워서 계속 열심히 하거든요.
	- 팀 내에서 분담은…
		- 적어주신것처럼 각자 싱글 모델을 만드는게 좋은것같아요.
			- 각자가 하고싶은 게 되게 많거든요!
			- 방법, 아키텍쳐 다 실험하시다가…
			- 좋은 아이디어가 나오면 공유해주시면 모든 팀원의 싱글점수가 올라가거든요.
- GPU 사는것 말고 NSML 클라우드 돌리시는것 어떻게 생각하시나요?
	- 어떤분이 질문하셨는지 모르겠는데… ㅋㅋㅋㅋㅋ
	- 저는 개인적으로는 GPU가 좋은것같아요.
		- NSML은 실시간으로 디버깅하기가 힘들어서 개인장비를 쓰거나, 캐글 노트북을 쓰거나, 구글 코랩을 쓰는걸 추천드립니다.
	- 공부목적이라면 캐글 노트북이 좋은 것 같아요.
		- 타인의 모델을 셀 by 셀로 다 가져와서 실행시켜보고, 변수를 다 확인할 수 있어요
	- 결론은 NSML은 고려하지 않는다
- 딥러닝 모델에서의 다양한 Parameter를 정하실 때 따로 tip이 있으신지 (ex. learning rate, layer수, Node수, scheduler 종류 등, 처음에 base로서 시도해보는 값은 이런게 있다~)
	- 저도 많은 경진대회를 나간 편인데, 해보니까 이미지냐/텍스트냐/정형데이터냐에 따라 다 다르구요.
		- 또 이미지같은경우도 어떤 이미지냐에 따라 달라요.
			- Adam, lr=0.001, 스케줄러=multistep-lr을 가장 많이 써봐요(잘못 들었다면 제보 부탁드립니다)
		- 텍스트같은경우는
			- warm-up(0부터 선형적으로 증가시켰다가 선형적으로 감소시키는 linear decay), lr=0.0001 (잘못 들었다면 제보 부탁드립니다)
		- 근데 이런건 사람마다 좀 달라요. 직감의 영향도 많이 받고.
		- 어떤게 좋은지는 다 돌려보셔야 될거에요.
	- 하시다보면 히든사이즈 같은 하이퍼파라미터들도 점점 감이 와요.
- 캐글의 진입장벽이 조금 높은 것 같은데, 공부할 때 대회를 고르는 팁이 있을까요?
	- 아까 질문주신거랑 비슷한거 같네요.
	- 공부목적으로 할 때에는 역시 팀 수가 많은 대회!
		- 이벤트도 많이 발생해요.
			- 고인물 삼촌들끼리 싸우는 것 구경 ㅎㅎ
- 마스터님이 지속적으로 캐글에 참여하게 되는 원동력이 무엇인가요?
	- 캐글을 하면 재밌어요.
	- 캐글 하시는 분들(캐글 코리아)하고 모임을 가지다 보면…
		- 캐글 중독자 분들도 계세요.
		- LOL같은거 하면 봇하고 하는것보다 사람하고 하는게 더 재밌잖아요(부모님 안부를 묻긴 하지만)
	- 개발역량을 지키고싶다? -> 캐글을 하며 좋은거같아요.
	- 캐글은 최신 논문을 알수 있어서도 좋지만, 쓸 수 있는 기술이 무엇인가를 캐글 경진대회에서 알기도 해요.
		- 써보면 성능이 어떤지 알잖아요.
- 캐글 상위 랭커가되면 아이비리그 박사 제안도 온다고 수업내용중에 나오는데 혹시 승낙하지 않은 이유가 있으신가요??
	- 영어문제도 있지만, 가족도 있고 나이도 있고 해서…
		- 제가 좀 동안인가요? ㅎㅎ
	- 너무 모험성이 크기도 해서…
	- 여러분들은 젊으시니까 기회가 오면 바로 승낙하세요!
- 일반적으로 Batch Size와 성능의 관계는 어떻게 되나요? 너무 작아도, 커도 안되겠지만 일반적으로 어떤 방향을 갖는게 성능에 도움이 될까요?
	- 저도 캐글을 처음할 때는 특정 배치사이즈가 좋은 줄 알았어요.
	- 근데 리더보드상
		- 퍼블릭에서 좋았던 게 프라이빗에서 안좋아지는 shake up을 봤어요.
			- 이런 경우에 배치사이즈에 따라서 특정 데이터셋에만 좋아지도록 오버피팅이 되는 경우가 있는것같아요.
	- 그래서 메모리 용량이 허용하는 한 최대한 크게 하는 편이구요.
		- 다만 학습데이터가 적을 때에는 너무 크게 하면 안좋긴해서…
		- 배치사이즈가 전체 데이터의 사이즈 10%보다는 적지만, 그 이하에서는 메모리 허용량 최대치로.
- Image Classification Task에서, Resize를 통한 Augmentation이 대체로 좋은 성능을 내는 것처럼 보여지는데, 일반화 할 수 있는 아이디어 일까요?
	- 제가 Augmentation을 이해한 건, 이미지 한장에 대해서 다양한 각도/변형에 대해 강하게 학습하기 위해 translation하거나 rand-crop(랜덤하게 잘라내는것), resize하는건데…
		- 이런것들을 적용해야만 한 이미지에 대해서 더 인식률이 높은 모델을 만들 수 있다고 생각하고 있어요.
	- 일반적으로 resize는 대부분 쓰이는것같아요.
		- 이미지 크기 문제도 있고
		- 아키텍쳐 크기별로 맞춰주는게 좋은 것 같아서.
- 마지막으로 참여하셨던 kaggle 의 EDA 스토리를 알려주세요
	- 탐색적 데이터분석말씀하시는거 맞을까요?
	- 저는 EDA를 열심히 하진 않고, 딥러닝을 좋아하구요.
		- 어떤 말이냐면, 딥러닝의 모토가 입력 데이터를 덜 건들면서 아키텍쳐를 건드려서 모델의 성능을 높이는것
		- DKT 대회(DSD? 2019) 나갔을 때도, 입력 데이터를 날것으로 넣고 아키텍쳐에 더 신경을 써보자! 하는 생각으로 했습니다.
		- 이건 모델링하시는 분이면 다들 공감하시지 않을까요?
- 단순히 “이거 해봤습니다” 로 끝나지 않을 하나의 스펙이 될 만한 방법이 있을까요?
	- 스펙으로는 캐글에 나가서 은메달을 따시면 좋을 것 같아요.
		- 은메달 따신 분들은 다 잘됐어요. 카카오/SKT…
		- 대학원도 좋은곳 들어가셨어요.
	- 캐글에서 좋은 성적 내신 분들이 아직 잘 없거든요. 여기서 얻은 점수를 어디서든 좋게 봐주시는것 같아요.
	- 최근에 기업 BEST를 꼽을 때, 수상실적으로 캐글을 고려하는 경우도 늘고 있습니다.
- 클라우드 컴퓨팅의 시간제한 같은 환경적 제약을 로컬 환경 컴퓨팅처럼 잘 다룰 수 있는 팁이 있는지 궁금합니다. 아주 비싼 모델연산을 돌릴 때 원격 서버 환경에서 효과적으로 logging, 오류가 나더라도 중간 결과를 잘 저장해 피해를 줄이고 효율적으로 디버깅하는 방법이 있을까요?
	- 저같은 경우 클라우드 컴퓨팅 환경을 잘 사용하지는 않아서…
		- 이건 제가 좋은 조언을 드리기는 힘들 것 같고.
		- 구글 클라우드를 썼다가 의도치않게 하루새 70만원정도가 나온적 있어서…
		- 제가 말씀드리면 문제가 될것같아 넘기겠습니다…ㅋㅋㅋ
- 모델성능을 최대한 높히기 위한 방법중에 Feature engineering을사용한다고 들었는데, 이게 무엇인지 그리고 많이 중요한 지 궁금합나다. 또한 이를 적용해보신 사례가 있으신가요?
	- 피쳐엔지니어링을 하는 가장 큰 이유가
		- ML/DL 모델이 아직 좀 멍청(?)해서.
		- 피쳐 엔지니어링을 잘 안해주면 좋은 결과를 못뽑는경우가 많아요.
		- 피쳐엔지니어링이 어떤 느낌이냐면
			- 판다스 데이터프레임같은걸 써서
			- 새로운 컬럼을 만들기도 하고, 기존 컬럼을 필요없어서 삭제하기도 해요.
		- 피쳐엔지니어링은 정형데이터쪽에 더 많이 쓰이게 되구요.
			- P스테이지 정형데이터 수업에서 더 좋은 내용들을 더 많이 배우실 수 있을 것같아요.
	- 최근 사례로 DKT 대회를 나갔을 때
		- 한 학생의 과거 히스토리를 보고 미래 결과를 예측하는거였는데
			- 과거 히스토리가 너무 길 경우에 집계하여 넣는 용도로 사용하기도 합니다.
			- (서일님 추가) 문제풀이 이력을 400개 까지만 넣을 수 있는 트랜스포머기반 모델의 출력에, 1000개 2000개 푼 유저의 히스토리 정보를 넣기 위해서 통계적 피처를 추가하는 경우가 있었습니다.
- competition에 참가하면 gpu 등의 장비를 오랫동안 돌려놓게 되는지? 그렇다면 어느 정도의 전기세가 나오고, 장비 교체 주기는 얼마나 되는지? 갖고 있는 GPU 자원을 효율적으로 사용할 수 있는 팁이 있으신가요? (ex 배치 사이즈 조절, 모니터링 팁 등)
	- 2080ti같은거 쓰시면… 가정 전기세는 누진이 되잖아요.
		- 하루에 8시간 기준으로 돌리면 한달에 한 8~10만원 정도 나올수 있구요.
		- 가정이 전기를 많이 안쓰는 편이면 3~4만원정도 나오기도 해요.
	- 저는 2080ti가 6대가 있는데(컴퓨터 3대)
		- 필요할 때만 켜고 필요하지 않을때는 껐어요.
	- 전기세 계산할 수 있는 사이트도 있는데
		- Power * 사용시간으로 전기세를 추정해볼수있어요.
- 혹시 대회에 막 참가해서 데이터를 파헤칠 때, 분석에 충분히 많은 시간을 투자한 뒤 인사이트를 모델링에 반영하시나요, 아니면 우선 모델링하여 리더보드 결과를 확인해본 뒤 본격적으로 분석을 진행하시나요?
	- 저는 경험이 많다 보니까 데이터를 가지고 리더보드 제출까지 빠르면 하루~ 늦으면 며칠정도.
	- 제출까지 파이프라인을 빠르게 보세요.
		- 제출까지 하루가 걸리면, 차라리 학습 데이터를 줄이거나, 더 좋은 GPU를 사용하세요.
		- 많은 반복실험을 해야해요.
	- 그 점수를 기반으로 피쳐엔지니어링/아키텍쳐변경/하이퍼파라미터 튜닝
- 캐글에서 극한으로 0.00001%의 점수를 쥐어짜는 것이 현업에서는 큰 의미를 가진다고 생각하지 않는데, 그런 점수에 과도하게 집중하게 되는 캐글의 양상?에 대해서 어떻게 생각하시는지 궁금합니다.
	- 그렇죠, 현업에서는 작은 숫자에 연연하진 않긴 하죠.
	- 0.00001 정도밖에 차이가 안나는건 아니고…
	- 캐글에서 점수를 올린다는건
		- 대회에 집중해서 문제/입력데이터/관련논문들을 열심히 파게되는데, 그 과정에서 얻는게 너무 많아요.
		- 레이스로 치면 운전을 모든 면에서 잘하시는것과 같아요.
		- 캐글을 잘한다는건 모델링 측면에서 모든 측면을 잘하게 됩니다.
			- 그러면 현업에서 일을 아주 잘하시지 않을까? 하고 생각하게 됩니다.
	- 경진대회에서 좋은 결과를 내기 위해 치열하게 노력하시는 분들은 현업에서도 좋은 성과를 내세요.
		- 왜냐하면, 경진대회를 위해 머신러닝 데이터를 모으거나 하진 않잖아요.
		- 기업들이 다 관심이 있어서 모아둔건데, 안되니까 캐글에 맡기거나 하는 경우도 있거든요.
		- 캐글의 문제가 워낙 현업과 밀접하기때문에, 노력하는 것 자체가 의미있다고 생각합니다.
- 앙상블 하는 과정에서 예측 변수가 연속형이라면 최종 추론 값 들의 평균을 낼 수 있지만 분류 문제처럼 범주형 변수라면 어떠한 방법으로 앙상블을 시도하는지 궁금합니다.
	- 범주형 변수라도 확률분포로 나오게 되고, 그 중 큰 값을 선택하게 되는데요.
	- 그냥 단순 평균내시면 됩니다.
	- 따로 voting하는 방법도 있는데, 제가볼 땐 평균내는게 제일 무난한거같아요.
- v1, v2, … 순서로 개별 폴더를 만들어 코드를 관리한다고 하셨는데 버전을 나누는 기준이 어떻게 되나요?
	- 귀찮지만 않으면 버전을 계속 키우시는걸 추천드립니다.
	- 사람이 하다보면 귀찮아서 그냥 원래 버젼에 코드를 덧붙이게되는데, 그럼 롤백이 힘들어요.
		- 그럼 복구하는데에 시간이 더 걸리게 돼요.
	- 웬만하면 결과를 한번 본 경우는, 개별 폴더를 만드시는것이 더 좋다고 생각합니다.
		- 이거 안담아두면 며칠 날리기도 해요.
- kaggle과 같은 대회에서 EDA와 전처리가 중요한 것으로 알고 있는데, EDA와 전처리에 대한 꿀팁들을 전수해주실 수 있으신가요?
	- 이 부분은 정말 대회마다 달라요.
	- P스테이지에서 다양한 경우를 접하실텐데, 다양한 대회를 할 수록 모든 경우에 통용되는경우는 없다는 걸 알게 되는거같아요.
		- 고인물들은 경험이 많아서 잘하거든요.
	- 혹시 처음 경험하시는거라면 [제가 쓴 책](https://book.naver.com/bookdb/book_detail.nhn?bid=17694145)이 있는데 참고하시면 좋지 않을까(ㅎㅎㅎㅎ)
- local CV와 public LB가 함께 올라가는 방법을 선택하라고 하셨는데, 강의에서 다룬 k-fold 방식외에 다른 방식이 있을까요?
	- 예외없이 거의 모든 대회에서 stratified k-fold를 많이 써요.
	- 쓸 수 없는 경우 -> 시계열 데이터같은 경우. 이런 경우는 다른걸 쓰긴 해요.
		- 이 부분은 P스테이지에서 다루고 있는걸로 알고있기 때문에 참고하시면 좋을것같아요.
- MultiLabel Classification Task의 경우에, Valid Set을 어떻게 구성하시나요? 레이블에 따른 층화추출 등으로 Dataset 구성이 가능할까요?
	- multilabel classificiation를 반영해서 나눠주는 방법이 따로 있을거에요.
	- multilabel classificiation 경진대회를 들어가보시면, 노트북으로 공유가 되어있을거에요. 라이브러리 이름은 기억이 안나네요.

## 캠퍼분들께 한 말씀

최근에 kaggle 고득점자를 채용하는 경우가 많은데, 아마 경진대회에서 현업에서 일을 잘하시기때문이 아닌가 합니다. P스테이지도 kaggle 형태로 competition을 만들었으니까, P스테이지 열심히 참여해주세요!