# 오피스아워 금(04.02) Baseline Code 및 Auto ML 실습

김보찬 멘토님의 꿀팁 세션

공유해주시는 PPT 자료 보충용입니다. 세션을 들으시고 보셔야만 이해가 될 수도 있습니다.
제가 7시 이후 참여가 어려워서 이후 내용은 짤려있습니다… ㅠㅠ 혹시 적어두신분은 댓글로 공유해주시면 정말 감사하겠습니다. 저도 궁금해서…

## 세션 내용

### Baseline code 설명

베이스라인 코드가 어떻게 이루어져있고, 왜 이렇게 이루어져있고, 모델 성능을 어떻게 올릴지 등에 대한 live coding을 진행했습니다.

- Notebook vs Python IDLE?

	- Notebook
		- 프레임워크에 익숙하지 않다면 추상적으로 되어있는 코드에서 바로 직관적으로 결과값을 확인할 수 있다.
		- 데이터셋의 결과, 모델 결과를 보고 싶을 때 사용하면 좋다
			- 모델의 성능들을 정성적으로 보기에 편하다.
		- remote DB 등에서 한번에 IO 로딩을 하고 나머지 코드들을 바꿔치기 하면서 할 수 있다. IDLE(프로젝트)는 매번 실행시킬때마다 로딩해야한다.
	- 프로젝트(IDLE)
		- 저는 더 선호합니다. 절대 대체할 수 없는 파이썬 IDE의 장점이 있습니다.
		- (질문) pycharm을 사용하시는데 특별한 이유가 있나요?
			- 좀 더 무거운 대신 파워풀한 기능이 많아서… 중독되어서 헤어나오지 못하고있습니다.
		- navigation 등으로 내부 소스코드, 파라미터 등을 훑어볼 수 있다는게 너무 좋습니다.
		- 리팩토링 시에 편합니다. 특정 변수를 잡아서 rename하면 전체 리팩토링이 됩니다.
			- 단축키는 추후에 따로 파일로 제공해주신다고 합니다.
		- 디버거 모드, remote interpreter도 너무 좋습니다.
		- Notebook의 단점은 (remote interpreter를 안쓰면) 로컬에 작업한 것이 서버에 동기화가 안됩니다. 서버에 접속할 수 없으면 코딩을 못하게 됩니다. 그런데 remote interpreter에 쓰면 로컬에서 작업한 내용이 서버로 동기화(업로드)됩니다.
		- 파이썬 구조화 / 아키텍쳐를 짜기에 편합니다.
			- 비슷한 기능끼리 잘 추상화해두고, 확장성과 재사용을 하기에 좋습니다.
			- 다양한 trial을 할 수 있게 모아두는게 중요하다(이현수 멘토님)
		- CLI(터미널)에서 프로젝트를 실행할 수 있습니다.
			- 노트북보다 한번 실행할 때 훨씬 편합니다.
			- versioning도 편합니다.

- Baseline code 기본 구성

	- PPT + 자정에 올라오는 베이스라인 코드 참조

- Basline code Usage

	- 다양한 하이퍼파라미터 세팅으로 학습을 진행해볼 수 있다.
	- 텐서보드로 학습 양상 실시간 확인이 가능합니다.
	- **Custom Module로 성능을 끌어올릴 수 있습니다.** <- 이게 핵심!

- 베이스라인 코드 시연

	- CLI 환경에서 parameter에 맞추어 argument를 넘길 수 있습니다(ex- `python train.py --epochs 10 --lr 0.01 --name mycode`)

	- 결과 확인은 Tensorboard에서 확인할 수 있습니다.

		- Tensorboard 사용법은 김태진 마스터님이 올려주신 방법 참조
			- (김태진 마스터님) AI STAGES의 텐서보드로 할당된 포트번호는 다를 수 있기 때문에, 본인의 서버 상태를 확인해야합니다!
		- 데이터셋이 불러온 Image도 확인하면서 무엇을 제대로 체크하지 못했는지 확인할수도 있습니다.

	- 소스코드 내부의 랜덤적인 부분이 많습니다(ex-초기화). 그런데 

		random seed

		를 고정하면 항상 똑같은 결과가 나오게 됩니다.

		- 이는 곧, 하이퍼파라미터 변경에 있어서 랜덤성을 전부 배제하여 같은 하이퍼파라미터에서는 완전히 동일한 결과를 나오게 하는 것입니다. 따라서 하이퍼파라미터가 어떤 모델 학습결과에 어떤 영향을 미치는지 확실히 확인할 수 있습니다.
		- random seed가 고정되면 불러오는 이미지셋의 (원래는 랜덤이었던) 순서도 동일합니다(텐서보드 이미지에서 확인할 수 있습니다)
		- (질문) 그렇다면 random seed도 하이퍼파라미터가 될 수 있을까요?

- Custom Module 실습

	- (꿀팁) IDLE의 navigation 기능을 사용하시면 정말 편합니다!(파일 찾기, 라이브러리 소스코드 뜯어보기, 파라미터 설명 찾기…)

	- Custom Model

		- 새로운 모델 class를 models.py에 정의합니다(정의된 template을 응용하여도 됩니다). ex - 

			```
			MyModel
			```

			- 일반적으로 모델 새로 정의하는 방법과 동일합니다…
				- 재사용되는 variable은 overwrite하는 것이 좀더 효율이 좋습니다.(ex- model(x)에 들어가는 x)

		- 이후, 

			```
			python train.py --epochs 10 --model MyModel
			```

			을 수행하면…

			- 새로 만든 모델을 이용하여 학습 가능!
			- 오픈소스로 가져온 모델을 사용해보거나, 내가 직접 만든 모델 아키텍쳐도 사용해보세요!

	- Custom Augmentation

		- 새로운 Augmentation을 정의합니다(디테일은 공식 문서를 참고하거나, 파라미터 힌트 등을 참조합시다.) - ex- `MyAugmentation`

		- 이후, 

			```
			python train.py --epochs 10 --augmentation MyAugmentation
			```

			을 수행하면…

			- 커스텀한 augmentation이 적용됩니다.

		- 적용한 augmentation은 텐서보드 이미지로 바로 확인할 수 있습니다!

	- 같은 방법으로 Custom Dataset도 가능합니다. 어렵지 않죠?

	- 이렇게 다양한 실험을 할 수 있고 비교하기 쉽게 만드는 것이 (디버깅에도 도움이 되기도 하고) 성능향상으로 직결됩니다.

	- LR scheduler 추가

		- 변수명을 가지고 로직을 추가하시면 됩니다.
			- 들어온 `argument=="특정 스케쥴러"`라면 해당 스케쥴러를 적용시키시면 됩니다.(if-else문 구현)
		- 템플릿을 만들어 저장해두시고 매번 갖다 붙여서 추가하시는게 편합니다.

### Auto ML 실습

모델 아키텍쳐, 하이퍼파라미터 설정 등은 사람이 했어야 했지만, 하이퍼파라미터까지 학습과정에서 알아서 정하도록 하겠다! -> 이것을 Auto ML이라고 부릅니다.(여러 방식들이 있지만, 크게 설명해서)

**Task 종류**

- NAS

	- 모델을 결정 할 때 일반적으로 사전 지식을 가지고 설정해야한다.
		- (뇌피셜로) 잔차를 학습하면 더 성능이 좋아지지 않을까? -> resNet 등…
	- 근데 이런 것까지도 하이퍼파라미터로 정의하고, 엄청 많은 iteration을 돌려서 최적의 아키텍쳐를 찾는다.
		- 따라서 기본으로 TPU 써서 며칠-몇달 정도 걸리는… 저세상 방식.
	- Nas를 통해 나온 모델 디자인은 패턴이 없습니다. 엄청 중구난방이에요. 사람이 디자인 한 방식에 비해서…
		- FPN은 사람이 만든거라서 깔끔한 모양이지만, 나머지 모델들은 NAS가 만든거라서 개판으로 생겼음.
	- 사실 EfficientNet, Swish도 AutoML을 이용해서 찾아낸 것입니다.

- 실습(MNIST set)

	- 사용하기 좋은 라이브러리 - 

		`MS NNI`

		- MS Azure과 같이 사용하면 시너지가 좋다(제대로 못들었습니다)

	- 설치 / 사용법 등은 Docs 찾아보세요!

	- 실험 과정 및 결과를 web url에서 볼 수 있습니다.

		- 어떤 하이퍼파라미터에서 성능이 얼마나오는지 확인할 수 있습니다.
		- 우상단의 Search space : 하이퍼파라미터 범위를 정해두고, 이 사이에서 탐색하도록 설정해둘 수 있습니다.

	- 그래프를 보면서 어떤 하이퍼파라미터가 어떤 형태여야 좀 더 효율적인지 볼 수 있습니다.

	- 근데 다 해두면 경우의수가 너무 많아져서 오래걸리니, 추천하는 방법은

		- 파라미터 하나나 두개 정도만 search space로 범위를 지정해두고, 나머지는 고정해두는게 더 실용적인 방법입니다.

- 실습(우리 베이스라인 코드에 적용시키기)

	- nnictl config(.yml 파일)을 리버스 엔지니어링 해봅시다.
		- 해당 파일을 열어 보면, 여러 설정값들이 나와 있습니다.
		- 주목할 값은 `search_space`와 `command=`입니다.
		- (놓쳤습니다) nni로 찾아보면 로그를 찍는것을 확인할 수 있는데, 이걸 인지를 하고 새로 코드를 짜봅니다.
		- 이 부분은 난해해서… 소스코드를 제공드리긴 하는데 ‘이렇게 할수있구나’ 정도로 그냥 알고 넘어가시면 될것같습니다.
		- (이 부분 뒤로는 시간이 없어 적지 못했습니다. 추가부탁드립니다!)

## 질문 Q&A

- Pycharm을 사용하려고 했는데, ssh와 연결해서 데이터를 사용하려면 로컬로 데이터를 다운로드 해야한다고 나오더라고요. 그래서 포기하고 vscode로 바꿨는데 ssh와 연결된 로컬 프로젝트에 데이터를 다운로드해도 되는건가요?
	- (김태진 마스터님)Pycharm에서 굳이 다운로드 받지 않고 서버 경로의 데이터 폴더를 지정할 수 있을거에요.
- 현재 가지고 있는 데이터 수가 18600개라고 하면 augmentation의 transform을 적용하면 transform된 18600개로 학습이 되나요?? 원본이미지+transform된 이미지=33200개로 학습이 되나요??..
	- 전자(18600개)로 학습됩니다.
	- (이현규 캠퍼님)대혁님 질문에 제가 알고있는 바는 이렇습니다.transform에 random 확률에 따라 변환을 하는 aug가 포함되어 있으면, 동일한 image더라도 매 epoch마다 다른 image가 학습 될 수 있다고 알고 있어요.
	- (질문) 후자처럼 데이터셋을 늘리는 것을 오버샘플링이라고 부르는건가요?
	- (질문) 후자처럼 데이터셋을 늘려서 하면 의미가 없나요 혹시??>… 아니면 해봐야 아는걸까요??
		- (김종헌 캠퍼님) 제가 위에서 말씀하신것처럼 오버샘플링을 몇번 해봤는데 비율 1대1로 늘리면 오버피팅 현상이 좀 나서 만약에 하게된다면 적절한 비율을 찾는게 중요할거같아요
- 이번 컴페티션에서 f1score 최대치로 어느정도예상하시나요
	- 80점(현재 최고)도 사실 예상보다 높았습니다…
	- 데이터 불균형이 있어서 사실 아주 높은 점수는 나오기 힘들거같아요.

Select a repo